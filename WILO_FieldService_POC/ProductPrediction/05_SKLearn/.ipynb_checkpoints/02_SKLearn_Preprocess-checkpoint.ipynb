{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Environment, Dataset\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.train.estimator import Estimator\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"39288a38-ff19-432c-8011-1cd9d0dff445\")\n",
    "ws = Workspace(subscription_id=\"793146d9-d4dc-4a73-9728-76c4ffd0cc0d\", resource_group=\"rg_dynamics_test\", workspace_name=\"resdynml1test\", auth=interactive_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experiment cfg\n",
    "with open(\"experiment_cfg.json\", \"r\") as cfg_file:\n",
    "    cfg = json.load(cfg_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/pipe.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/pipe.py\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names, dtype):\n",
    "        self.attribute_names = attribute_names\n",
    "        self.dtype = dtype\n",
    "    def fit(self, X, y=None):\n",
    "        return self        \n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].astype(self.dtype).values\n",
    "\n",
    "class MultiHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, delimiter=None):\n",
    "        self.delimiter = delimiter\n",
    "    def fit(self, X, y=None):\n",
    "        self.col_cats = {}\n",
    "        for col in range(X.shape[1]):\n",
    "            cats = set()\n",
    "            for row in range(X.shape[0]):\n",
    "                if self.delimiter:\n",
    "                    for cat in X[row,col].split(self.delimiter):\n",
    "                        if not cat.strip() == '':\n",
    "                            cats.add(cat.strip())\n",
    "                else:\n",
    "                    cats.add(X[row,col])\n",
    "            self.col_cats[col] = list(cats)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_tr = []\n",
    "        for col in range(X.shape[1]):\n",
    "            X_enc = np.zeros([X.shape[0], len(self.col_cats[col])])\n",
    "            for row in range(X.shape[0]):\n",
    "                if self.delimiter:\n",
    "                    cats = str(X[row,col]).split(self.delimiter)\n",
    "                    for col_cat_idx in range(len(self.col_cats[col])):\n",
    "                        if self.col_cats[col][col_cat_idx] in cats:\n",
    "                            X_enc[row, col_cat_idx] = 1\n",
    "                else:\n",
    "                    for col_cat_idx in range(len(self.col_cats[col])):\n",
    "                        if self.col_cats[col][col_cat_idx] == X[row,col]:\n",
    "                            X_enc[row, col_cat_idx] = 1\n",
    "            X_enc = np.array(X_enc)\n",
    "            X_tr.append(X_enc)\n",
    "        X_tr = np.concatenate(X_tr, axis=1)\n",
    "        return X_tr\n",
    "    \n",
    "def create_pipelines(cfg):\n",
    "    \n",
    "    # Pipeline for multilabel features\n",
    "    multi_pipe = Pipeline([\n",
    "        ('multi_feat_select', DataFrameSelector(cfg['multi_cols'], str)),\n",
    "        ('multi_encode', MultiHotEncoder(delimiter=' '))\n",
    "    ])\n",
    "    \n",
    "    # combine features\n",
    "    feat_union = FeatureUnion([\n",
    "        ('multi_features', multi_pipe)\n",
    "    ])\n",
    "    \n",
    "    # preprocess all features\n",
    "    all_feat_pipe = Pipeline([\n",
    "        ('all_features_pipe', feat_union),\n",
    "#         ('all_feautres_pca', PCA(n_components=0.8, svd_solver = 'full'))\n",
    "    ])\n",
    "    \n",
    "    # Pipeline for multi target cols\n",
    "    multi_target_pipe = Pipeline([\n",
    "        ('target_select', DataFrameSelector(cfg['multi_target_cols'], str)),\n",
    "        ('target_encode', MultiHotEncoder(delimiter=' '))\n",
    "    ])\n",
    "\n",
    "    # Pipeline for numerical target cols\n",
    "    num_target_pipe = Pipeline([\n",
    "        ('num_feature_select', DataFrameSelector(cfg['num_target_cols'], float))\n",
    "    ])\n",
    "    \n",
    "    all_target_pipe = FeatureUnion([\n",
    "        ('num_targets', num_target_pipe),\n",
    "        ('multi_targets', multi_target_pipe)\n",
    "    ])\n",
    "\n",
    "    return { 'feature_pipe': all_feat_pipe, 'target_pipe': all_target_pipe }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/preprocess.py\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from pipe import create_pipelines\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('--input', dest='prepared_data')\n",
    "parser.add_argument('--output', dest='preprocessed_data')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# load datasets\n",
    "if args.prepared_data:\n",
    "    df = pd.read_csv(args.prepared_data + '/prepared_data.csv', sep=';', header=0)\n",
    "else:\n",
    "    df = run.input_datasets['df_prepared'].to_pandas_dataframe()\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# split data (test data from last t_test years)\n",
    "t_test = 0.5\n",
    "df_train = df[df['Start']<(datetime.datetime.today() - datetime.timedelta(days=t_test*365))]\n",
    "df_test = df[df['Start']>=(datetime.datetime.today() - datetime.timedelta(days=t_test*365))]\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# select columns for training\n",
    "cfg = {}\n",
    "cfg['multi_cols'] = ['Symptoms', 'ProductId', 'Country']\n",
    "cfg['num_target_cols'] = ['duration']\n",
    "cfg['multi_target_cols'] = ['ProductNr']\n",
    "\n",
    "# create pipeline\n",
    "pipelines = create_pipelines(cfg)\n",
    "\n",
    "# fit pipelines and transform data\n",
    "X_train = pipelines['feature_pipe'].fit_transform(df_train)\n",
    "y_train = pipelines['target_pipe'].fit_transform(df_train)\n",
    "X_test = pipelines['feature_pipe'].transform(df_test)\n",
    "y_test = pipelines['target_pipe'].transform(df_test)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# rename columns\n",
    "feature_columns = [ 'feat_'+ str(i) for i in range(X_train.shape[1])]\n",
    "target_columns = [ 'target_'+ str(i) for i in range(y_train.shape[1])]\n",
    "\n",
    "df_train = pd.concat([\n",
    "    pd.DataFrame(X_train, columns=feature_columns),\n",
    "    pd.DataFrame(y_train, columns=target_columns)\n",
    "], axis=1)\n",
    "\n",
    "df_test = pd.concat([\n",
    "    pd.DataFrame(X_test, columns=feature_columns),\n",
    "    pd.DataFrame(y_test, columns=target_columns)\n",
    "], axis=1)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# save train and test data\n",
    "path = args.preprocessed_data if args.preprocessed_data else './outputs'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "df_train.to_csv(path + '/train_data.csv', sep=';', header=True, index=False)\n",
    "df_test.to_csv(path + '/test_data.csv', sep=';', header=True, index=False)\n",
    "\n",
    "# save pipelines\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(pipelines, './outputs/pipelines.pkl')\n",
    "\n",
    "###########################################################\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = Estimator(entry_script='preprocess.py', source_directory='src', \n",
    "              inputs=[ws.datasets[cfg['prepared_data_dataset']].as_named_input('df_prepared')],\n",
    "              compute_target=ws.compute_targets['mlcompute'], environment_definition=ws.environments[cfg['env_name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: SKLearnPrediction_1592820992_186cf9c8\n",
      "Web View: https://ml.azure.com/experiments/SKLearnPrediction/runs/SKLearnPrediction_1592820992_186cf9c8?wsid=/subscriptions/793146d9-d4dc-4a73-9728-76c4ffd0cc0d/resourcegroups/rg_dynamics_test/workspaces/resdynml1test\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_06237a7255720d71d9b956997d5eac9756b9fead4286246963d4513dd31e5db9_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2020-06-22T10:20:33Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2020-06-22T10:20:33Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "2020-06-22T10:20:33Z Starting output-watcher...\n",
      "2020-06-22T10:20:33Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_c14e68a5a54beac144cd751fe11b91c5\n",
      "a1298f4ce990: Pulling fs layer\n",
      "04a3282d9c4b: Pulling fs layer\n",
      "9b0d3db6dc03: Pulling fs layer\n",
      "8269c605f3f1: Pulling fs layer\n",
      "6504d449e70c: Pulling fs layer\n",
      "4e38f320d0d4: Pulling fs layer\n",
      "b0a763e8ee03: Pulling fs layer\n",
      "11917a028ca4: Pulling fs layer\n",
      "a6c378d11cbf: Pulling fs layer\n",
      "6cc007ad9140: Pulling fs layer\n",
      "6c1698a608f3: Pulling fs layer\n",
      "000aacc20dee: Pulling fs layer\n",
      "921e47b34d8d: Pulling fs layer\n",
      "79aa1f3566b6: Pulling fs layer\n",
      "114594c89ae1: Pulling fs layer\n",
      "1f700cc39777: Pulling fs layer\n",
      "8269c605f3f1: Waiting\n",
      "6504d449e70c: Waiting\n",
      "4e38f320d0d4: Waiting\n",
      "b0a763e8ee03: Waiting\n",
      "11917a028ca4: Waiting\n",
      "a6c378d11cbf: Waiting\n",
      "6cf3cc306b86: Pulling fs layer\n",
      "6cf3cc306b86: Waiting\n",
      "6c1698a608f3: Waiting\n",
      "000aacc20dee: Waiting\n",
      "921e47b34d8d: Waiting\n",
      "79aa1f3566b6: Waiting\n",
      "114594c89ae1: Waiting\n",
      "1f700cc39777: Waiting\n",
      "6cc007ad9140: Waiting\n",
      "9b0d3db6dc03: Verifying Checksum\n",
      "9b0d3db6dc03: Download complete\n",
      "04a3282d9c4b: Verifying Checksum\n",
      "04a3282d9c4b: Download complete\n",
      "a1298f4ce990: Download complete\n",
      "8269c605f3f1: Verifying Checksum\n",
      "8269c605f3f1: Download complete\n",
      "4e38f320d0d4: Verifying Checksum\n",
      "4e38f320d0d4: Download complete\n",
      "6504d449e70c: Verifying Checksum\n",
      "6504d449e70c: Download complete\n",
      "b0a763e8ee03: Verifying Checksum\n",
      "b0a763e8ee03: Download complete\n",
      "a1298f4ce990: Pull complete\n",
      "6cc007ad9140: Verifying Checksum\n",
      "6cc007ad9140: Download complete\n",
      "04a3282d9c4b: Pull complete\n",
      "9b0d3db6dc03: Pull complete\n",
      "8269c605f3f1: Pull complete\n",
      "11917a028ca4: Verifying Checksum\n",
      "11917a028ca4: Download complete\n",
      "6c1698a608f3: Verifying Checksum\n",
      "6c1698a608f3: Download complete\n",
      "000aacc20dee: Verifying Checksum\n",
      "000aacc20dee: Download complete\n",
      "921e47b34d8d: Verifying Checksum\n",
      "921e47b34d8d: Download complete\n",
      "79aa1f3566b6: Verifying Checksum\n",
      "79aa1f3566b6: Download complete\n",
      "114594c89ae1: Verifying Checksum\n",
      "114594c89ae1: Download complete\n",
      "6cf3cc306b86: Download complete\n",
      "a6c378d11cbf: Verifying Checksum\n",
      "a6c378d11cbf: Download complete\n",
      "6504d449e70c: Pull complete\n",
      "4e38f320d0d4: Pull complete\n",
      "1f700cc39777: Verifying Checksum\n",
      "1f700cc39777: Download complete\n",
      "b0a763e8ee03: Pull complete\n",
      "11917a028ca4: Pull complete\n",
      "a6c378d11cbf: Pull complete\n",
      "6cc007ad9140: Pull complete\n",
      "6c1698a608f3: Pull complete\n",
      "000aacc20dee: Pull complete\n",
      "921e47b34d8d: Pull complete\n",
      "79aa1f3566b6: Pull complete\n",
      "114594c89ae1: Pull complete\n",
      "1f700cc39777: Pull complete\n",
      "6cf3cc306b86: Pull complete\n",
      "Digest: sha256:7599d0a6023b356a998541c47fbac5f1c5fa1703ab6a07da45ad6b75da1ee74d\n",
      "Status: Downloaded newer image for resdynml1tes2b0154b9.azurecr.io/azureml/azureml_c14e68a5a54beac144cd751fe11b91c5:latest\n",
      "55cbcdc682d7d8f32ff1bbd1e5f8f8052e67574487b8b30756341cfa000f78d0\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_06237a7255720d71d9b956997d5eac9756b9fead4286246963d4513dd31e5db9_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Entering job preparation. Current time:2020-06-22T10:21:44.884019\n",
      "Starting job preparation. Current time:2020-06-22T10:21:45.597437\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Entering context manager injector. Current time:2020-06-22T10:21:49.673671\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 114\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ preprocess.py ] with arguments: []\n",
      "After variable expansion, calling script [ preprocess.py ] with arguments: []\n",
      "\n",
      "/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/azureml/dataprep/api/dataflow.py:717: UserWarning: Using alternate reader. Inconsistent or mixed schemas detected across partitions: partition had different number of columns. The first partition has 7 columns. Found partition has 14 columns.\n",
      "First partition columns (ordered): ['Job Card.JobCard Number', 'ProductId', 'ProductNr', 'Symptoms', 'Start', 'End', 'duration']\n",
      "Found Partition has columns (ordered): ['Job Card.JobCard Number', 'ProductId', 'ProductNr', 'Symptoms', 'Start', 'End', 'duration', 'Column8', 'Column9', 'Column10', 'Column11', 'Column12', 'Column13', 'Column14']\n",
      "  warnings.warn('Using alternate reader. ' + reason)\n",
      "\n",
      "############################################################################################\n",
      "\n",
      "Index(['Job Card.JobCard Number', 'ProductId', 'ProductNr', 'Symptoms',\n",
      "       'Start', 'End', 'duration', 'Column8', 'Column9', 'Column10',\n",
      "       'Column11', 'Column12', 'Column13', 'Column14'],\n",
      "      dtype='object')\n",
      "\n",
      "############################################################################################\n",
      "\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 114\n",
      "\n",
      "\n",
      "The experiment failed. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.48316478729248047 seconds\n",
      "Traceback (most recent call last):\n",
      "  File \"preprocess.py\", line 33, in <module>\n",
      "    df_train = df[df['Start']<(datetime.datetime.today() - datetime.timedelta(days=t_test*365))]\n",
      "  File \"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/common.py\", line 64, in new_method\n",
      "    return method(self, other)\n",
      "  File \"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/__init__.py\", line 529, in wrapper\n",
      "    res_values = comparison_op(lvalues, rvalues, op)\n",
      "  File \"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/array_ops.py\", line 247, in comparison_op\n",
      "    res_values = comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n",
      "  File \"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/array_ops.py\", line 57, in comp_method_OBJECT_ARRAY\n",
      "    result = libops.scalar_compare(x.ravel(), y, op)\n",
      "  File \"pandas/_libs/ops.pyx\", line 96, in pandas._libs.ops.scalar_compare\n",
      "TypeError: '<' not supported between instances of 'str' and 'datetime.datetime'\n",
      "\n",
      "2020/06/22 10:22:13 mpirun version string: {\n",
      "Intel(R) MPI Library for Linux* OS, Version 2018 Update 3 Build 20180411 (id: 18329)\n",
      "Copyright 2003-2018 Intel Corporation.\n",
      "}\n",
      "2020/06/22 10:22:13 MPI publisher: intel ; version: 2018\n",
      "2020/06/22 10:22:13 Process Exiting with Code:  1\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_06237a7255720d71d9b956997d5eac9756b9fead4286246963d4513dd31e5db9_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Entering job release. Current time:2020-06-22T10:22:14.546816\n",
      "Starting job release. Current time:2020-06-22T10:22:15.551423\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 340\n",
      "Entering context manager injector. Current time:2020-06-22T10:22:15.574603\n",
      "Job release is complete. Current time:2020-06-22T10:22:17.255918\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: SKLearnPrediction_1592820992_186cf9c8\n",
      "Web View: https://ml.azure.com/experiments/SKLearnPrediction/runs/SKLearnPrediction_1592820992_186cf9c8?wsid=/subscriptions/793146d9-d4dc-4a73-9728-76c4ffd0cc0d/resourcegroups/rg_dynamics_test/workspaces/resdynml1test\n",
      "\n",
      "Warnings:\n",
      "{\n",
      "  \"error\": {\n",
      "    \"code\": \"UserError\",\n",
      "    \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\",\n",
      "    \"messageFormat\": null,\n",
      "    \"messageParameters\": null,\n",
      "    \"referenceCode\": null,\n",
      "    \"detailsUri\": null,\n",
      "    \"target\": null,\n",
      "    \"details\": [],\n",
      "    \"innerError\": null,\n",
      "    \"debugInfo\": null\n",
      "  },\n",
      "  \"correlation\": {\n",
      "    \"operation\": null,\n",
      "    \"request\": \"b73e1181ddd278de\"\n",
      "  },\n",
      "  \"environment\": \"westeurope\",\n",
      "  \"location\": \"westeurope\",\n",
      "  \"time\": \"2020-06-22T10:22:21.2070203+00:00\",\n",
      "  \"componentName\": \"execution-worker\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with TypeError: '<' not supported between instances of 'str' and 'datetime.datetime'\",\n        \"detailsUri\": \"https://aka.ms/azureml-known-errors\",\n        \"details\": [],\n        \"debugInfo\": {\n            \"type\": \"TypeError\",\n            \"message\": \"'<' not supported between instances of 'str' and 'datetime.datetime'\",\n            \"stackTrace\": \"  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/resdynml1test/azureml/sklearnprediction_1592820992_186cf9c8/mounts/workspaceblobstore/azureml/SKLearnPrediction_1592820992_186cf9c8/azureml-setup/context_manager_injector.py\\\", line 148, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/runpy.py\\\", line 263, in run_path\\n    pkg_name=pkg_name, script_name=fname)\\n  File \\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/runpy.py\\\", line 96, in _run_module_code\\n    mod_name, mod_spec, pkg_name, script_name)\\n  File \\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"preprocess.py\\\", line 33, in <module>\\n    df_train = df[df['Start']<(datetime.datetime.today() - datetime.timedelta(days=t_test*365))]\\n  File \\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/common.py\\\", line 64, in new_method\\n    return method(self, other)\\n  File \\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/__init__.py\\\", line 529, in wrapper\\n    res_values = comparison_op(lvalues, rvalues, op)\\n  File \\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/array_ops.py\\\", line 247, in comparison_op\\n    res_values = comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\\n  File \\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/array_ops.py\\\", line 57, in comp_method_OBJECT_ARRAY\\n    result = libops.scalar_compare(x.ravel(), y, op)\\n  File \\\"pandas/_libs/ops.pyx\\\", line 96, in pandas._libs.ops.scalar_compare\\n\"\n        },\n        \"messageParameters\": {}\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with TypeError: '<' not supported between instances of 'str' and 'datetime.datetime'\\\",\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-known-errors\\\",\\n        \\\"details\\\": [],\\n        \\\"debugInfo\\\": {\\n            \\\"type\\\": \\\"TypeError\\\",\\n            \\\"message\\\": \\\"'<' not supported between instances of 'str' and 'datetime.datetime'\\\",\\n            \\\"stackTrace\\\": \\\"  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/resdynml1test/azureml/sklearnprediction_1592820992_186cf9c8/mounts/workspaceblobstore/azureml/SKLearnPrediction_1592820992_186cf9c8/azureml-setup/context_manager_injector.py\\\\\\\", line 148, in execute_with_context\\\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\\\\\"__main__\\\\\\\")\\\\n  File \\\\\\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/runpy.py\\\\\\\", line 263, in run_path\\\\n    pkg_name=pkg_name, script_name=fname)\\\\n  File \\\\\\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/runpy.py\\\\\\\", line 96, in _run_module_code\\\\n    mod_name, mod_spec, pkg_name, script_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/runpy.py\\\\\\\", line 85, in _run_code\\\\n    exec(code, run_globals)\\\\n  File \\\\\\\"preprocess.py\\\\\\\", line 33, in <module>\\\\n    df_train = df[df['Start']<(datetime.datetime.today() - datetime.timedelta(days=t_test*365))]\\\\n  File \\\\\\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/common.py\\\\\\\", line 64, in new_method\\\\n    return method(self, other)\\\\n  File \\\\\\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/__init__.py\\\\\\\", line 529, in wrapper\\\\n    res_values = comparison_op(lvalues, rvalues, op)\\\\n  File \\\\\\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/array_ops.py\\\\\\\", line 247, in comparison_op\\\\n    res_values = comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\\\\n  File \\\\\\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/array_ops.py\\\\\\\", line 57, in comp_method_OBJECT_ARRAY\\\\n    result = libops.scalar_compare(x.ravel(), y, op)\\\\n  File \\\\\\\"pandas/_libs/ops.pyx\\\\\\\", line 96, in pandas._libs.ops.scalar_compare\\\\n\\\"\\n        },\\n        \\\"messageParameters\\\": {}\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c06bceba7052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'experiment_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    679\u001b[0m                     \u001b[0mfile_handle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                     \u001b[0mwait_post_processing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_post_processing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m                     raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    682\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, file_handle, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with TypeError: '<' not supported between instances of 'str' and 'datetime.datetime'\",\n        \"detailsUri\": \"https://aka.ms/azureml-known-errors\",\n        \"details\": [],\n        \"debugInfo\": {\n            \"type\": \"TypeError\",\n            \"message\": \"'<' not supported between instances of 'str' and 'datetime.datetime'\",\n            \"stackTrace\": \"  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/resdynml1test/azureml/sklearnprediction_1592820992_186cf9c8/mounts/workspaceblobstore/azureml/SKLearnPrediction_1592820992_186cf9c8/azureml-setup/context_manager_injector.py\\\", line 148, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/runpy.py\\\", line 263, in run_path\\n    pkg_name=pkg_name, script_name=fname)\\n  File \\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/runpy.py\\\", line 96, in _run_module_code\\n    mod_name, mod_spec, pkg_name, script_name)\\n  File \\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"preprocess.py\\\", line 33, in <module>\\n    df_train = df[df['Start']<(datetime.datetime.today() - datetime.timedelta(days=t_test*365))]\\n  File \\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/common.py\\\", line 64, in new_method\\n    return method(self, other)\\n  File \\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/__init__.py\\\", line 529, in wrapper\\n    res_values = comparison_op(lvalues, rvalues, op)\\n  File \\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/array_ops.py\\\", line 247, in comparison_op\\n    res_values = comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\\n  File \\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/array_ops.py\\\", line 57, in comp_method_OBJECT_ARRAY\\n    result = libops.scalar_compare(x.ravel(), y, op)\\n  File \\\"pandas/_libs/ops.pyx\\\", line 96, in pandas._libs.ops.scalar_compare\\n\"\n        },\n        \"messageParameters\": {}\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with TypeError: '<' not supported between instances of 'str' and 'datetime.datetime'\\\",\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-known-errors\\\",\\n        \\\"details\\\": [],\\n        \\\"debugInfo\\\": {\\n            \\\"type\\\": \\\"TypeError\\\",\\n            \\\"message\\\": \\\"'<' not supported between instances of 'str' and 'datetime.datetime'\\\",\\n            \\\"stackTrace\\\": \\\"  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/resdynml1test/azureml/sklearnprediction_1592820992_186cf9c8/mounts/workspaceblobstore/azureml/SKLearnPrediction_1592820992_186cf9c8/azureml-setup/context_manager_injector.py\\\\\\\", line 148, in execute_with_context\\\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\\\\\"__main__\\\\\\\")\\\\n  File \\\\\\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/runpy.py\\\\\\\", line 263, in run_path\\\\n    pkg_name=pkg_name, script_name=fname)\\\\n  File \\\\\\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/runpy.py\\\\\\\", line 96, in _run_module_code\\\\n    mod_name, mod_spec, pkg_name, script_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/runpy.py\\\\\\\", line 85, in _run_code\\\\n    exec(code, run_globals)\\\\n  File \\\\\\\"preprocess.py\\\\\\\", line 33, in <module>\\\\n    df_train = df[df['Start']<(datetime.datetime.today() - datetime.timedelta(days=t_test*365))]\\\\n  File \\\\\\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/common.py\\\\\\\", line 64, in new_method\\\\n    return method(self, other)\\\\n  File \\\\\\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/__init__.py\\\\\\\", line 529, in wrapper\\\\n    res_values = comparison_op(lvalues, rvalues, op)\\\\n  File \\\\\\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/array_ops.py\\\\\\\", line 247, in comparison_op\\\\n    res_values = comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\\\\n  File \\\\\\\"/azureml-envs/azureml_42df74e95cf2de1f301b9fba9e8035c0/lib/python3.6/site-packages/pandas/core/ops/array_ops.py\\\\\\\", line 57, in comp_method_OBJECT_ARRAY\\\\n    result = libops.scalar_compare(x.ravel(), y, op)\\\\n  File \\\\\\\"pandas/_libs/ops.pyx\\\\\\\", line 96, in pandas._libs.ops.scalar_compare\\\\n\\\"\\n        },\\n        \\\"messageParameters\\\": {}\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "exp = Experiment(ws, cfg['experiment_name'])\n",
    "run = exp.submit(est)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading artifacts/train_data.pkl\n",
      "Uploaded artifacts/train_data.pkl, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', './SKLearnPrediction')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"b29d3ea3-3f43-40d0-82cd-c2f7b71cee28\",\n",
       "    \"name\": \"SKLearnTrainData\",\n",
       "    \"version\": 2,\n",
       "    \"workspace\": \"Workspace.create(name='resdynml1test', subscription_id='793146d9-d4dc-4a73-9728-76c4ffd0cc0d', resource_group='rg_dynamics_test')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.download_file('outputs/train_data.csv', output_file_path='artifacts/train_data.csv')\n",
    "ds = ws.datastores[cfg['storage']]\n",
    "data_ref = ds.upload_files(['artifacts/train_data.csv'], target_path='./'+cfg['experiment_name'], overwrite=True)\n",
    "preprocessed_train_data_dataset = Dataset.Tabular.from_delimited_files(data_ref, separator=';', header=True, infer_column_types=True)\n",
    "preprocessed_train_data_dataset.register(ws, cfg['train_dataset'], create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading artifacts/test_data.pkl\n",
      "Uploaded artifacts/test_data.pkl, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', './SKLearnPrediction')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"d154df9d-5eb2-4a20-83fa-3e398ccfbcb1\",\n",
       "    \"name\": \"SKLearnTestData\",\n",
       "    \"version\": 2,\n",
       "    \"workspace\": \"Workspace.create(name='resdynml1test', subscription_id='793146d9-d4dc-4a73-9728-76c4ffd0cc0d', resource_group='rg_dynamics_test')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.download_file('outputs/test_data.csv', output_file_path='artifacts/test_data.csv')\n",
    "ds = ws.datastores[cfg['storage']]\n",
    "data_ref = ds.upload_files(['artifacts/test_data.csv'], target_path='./'+cfg['experiment_name'], overwrite=True)\n",
    "preprocessed_test_data_dataset = Dataset.Tabular.from_delimited_files(data_ref, separator=';', header=True, infer_column_types=True)\n",
    "preprocessed_test_data_dataset.register(ws, cfg['test_dataset'], create_new_version=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Pipelines (as Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='resdynml1test', subscription_id='793146d9-d4dc-4a73-9728-76c4ffd0cc0d', resource_group='rg_dynamics_test'), name=SKLearnPreprocessPipeline, id=SKLearnPreprocessPipeline:2, version=2, tags={}, properties={})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.register_model(cfg['PreprocessPipeline'], 'outputs/pipelines.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
