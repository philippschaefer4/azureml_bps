{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Dataset\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.train.estimator import Estimator\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"39288a38-ff19-432c-8011-1cd9d0dff445\")\n",
    "ws = Workspace(subscription_id=\"793146d9-d4dc-4a73-9728-76c4ffd0cc0d\", resource_group=\"rg_dynamics_test\", workspace_name=\"resdynml1test\", auth=interactive_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experiment cfg\n",
    "with open(\"experiment_cfg.json\", \"r\") as cfg_file:\n",
    "    cfg = json.load(cfg_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/prepare.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/prepare.py\n",
    "\n",
    "from azureml.core import Run\n",
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('--output', dest='prepared_data')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# load datasets\n",
    "df_symptoms = run.input_datasets['symptomcodes'].to_pandas_dataframe()\n",
    "df = run.input_datasets['df_raw'].to_pandas_dataframe()\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# get only data from last t years\n",
    "t = 3\n",
    "df = df[df['Job Card.Date Start Work']>(datetime.datetime.today() - datetime.timedelta(days=t*365))]\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# clean data\n",
    "df = df.replace(['', '0', '-', '000','N/A'], np.nan)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# combine Component/Failure Code in train data\n",
    "df = pd.concat([df, pd.DataFrame(df.apply(lambda x: (x['Job Card.ComponentCode'],x['Job Card.FailureCode']), axis=1), columns=['CompFail'])], axis=1)\n",
    "\n",
    "# combine Component/Failure Code in symptom table\n",
    "df_symptoms = df_symptoms[['ComponentCode', 'FailureCode', 'Symptom1', 'Symptom2', 'Symptom3', 'Symptom4']]\n",
    "df_symptoms = pd.concat([df_symptoms, pd.DataFrame(df_symptoms.apply(lambda x: (x['ComponentCode'],x['FailureCode']),axis=1), columns=['CompFail'])],axis=1)\n",
    "\n",
    "# merge train data on symptoms\n",
    "df = pd.merge(df, df_symptoms, on='CompFail', how='left')\n",
    "df = pd.concat([df, pd.DataFrame(df[['Symptom1', 'Symptom2', 'Symptom3', 'Symptom4']].apply(lambda x: tuple([ x[col] for col in ['Symptom1','Symptom2','Symptom3','Symptom4'] if str(x[col]) != 'None' ]), axis=1), columns=['Symptoms'])], axis=1)\n",
    "\n",
    "# remove rows with no symptoms\n",
    "df = df[df['Symptoms']!=()]\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# merge into one row per case\n",
    "df = df.groupby('Job Card.JobCard Number').apply(lambda x: pd.Series({\n",
    "    'ProductId': ' '.join(x['Installed Base.InstalledBase ProductID'].unique()),\n",
    "    'Country': ' '.join(x['Location.Country'].unique()),\n",
    "    'Symptoms': ' '.join(map(str, list(set(x['Symptoms'].sum())))),\n",
    "    'ProductNrs': ' '.join(x['Product.Product Number'].unique()),\n",
    "    'Start': x['Job Card.Date Start Work'].min(),\n",
    "    'End': x['Job Card.Date End Work'].max()\n",
    "  })).reset_index()\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "# split data (test data from last t_test years)\n",
    "t_test = 0.5\n",
    "df_train = df[df['Start']<(datetime.datetime.today() - datetime.timedelta(days=t_test*365))]\n",
    "df_test = df[df['Start']>=(datetime.datetime.today() - datetime.timedelta(days=t_test*365))]\n",
    "\n",
    "# save train and test data\n",
    "path = arg.prepared_data if args.prepared_data else './outputs'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "df_train.to_csv(path + '/train_data.csv', sep=';', header=True, index=False)\n",
    "df_test.to_csv(path + '/test_data.csv', sep=';', header=True, index=False)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = Estimator(entry_script='prepare.py', source_directory='src', \n",
    "              inputs=[   ws.datasets[cfg['symptomcodes_dataset']].as_named_input('symptomcodes'), \n",
    "                         ws.datasets[cfg['raw_data_dataset']].as_named_input('df_raw')       ],\n",
    "              compute_target='local', environment_definition=ws.environments[cfg['env_name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: LookUpPrediction_1592829616_abf28b61\n",
      "Web View: https://ml.azure.com/experiments/LookUpPrediction/runs/LookUpPrediction_1592829616_abf28b61?wsid=/subscriptions/793146d9-d4dc-4a73-9728-76c4ffd0cc0d/resourcegroups/rg_dynamics_test/workspaces/resdynml1test\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Entering context manager injector. Current time:2020-06-22T12:40:18.183462\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 8\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ prepare.py ] with arguments: []\n",
      "After variable expansion, calling script [ prepare.py ] with arguments: []\n",
      "\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 8\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service.\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.17834973335266113 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: LookUpPrediction_1592829616_abf28b61\n",
      "Web View: https://ml.azure.com/experiments/LookUpPrediction/runs/LookUpPrediction_1592829616_abf28b61?wsid=/subscriptions/793146d9-d4dc-4a73-9728-76c4ffd0cc0d/resourcegroups/rg_dynamics_test/workspaces/resdynml1test\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'LookUpPrediction_1592829616_abf28b61',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-06-22T12:40:17.517455Z',\n",
       " 'endTimeUtc': '2020-06-22T12:45:03.819862Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': 'a602af5d-f404-4baa-898a-1ff229aff30f'},\n",
       " 'inputDatasets': [{'dataset': {'id': '02e6cb83-4d0c-42b2-bbef-e103c74b3a3c'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'df_raw', 'mechanism': 'Direct'}}, {'dataset': {'id': '88af5740-1a1b-4e09-8129-d3c538680909'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'symptomcodes', 'mechanism': 'Direct'}}],\n",
       " 'runDefinition': {'script': 'prepare.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'df_raw': {'dataLocation': {'dataset': {'id': '02e6cb83-4d0c-42b2-bbef-e103c74b3a3c',\n",
       "      'name': None,\n",
       "      'version': None},\n",
       "     'dataPath': None},\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'df_raw',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False},\n",
       "   'symptomcodes': {'dataLocation': {'dataset': {'id': '88af5740-1a1b-4e09-8129-d3c538680909',\n",
       "      'name': None,\n",
       "      'version': None},\n",
       "     'dataPath': None},\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'symptomcodes',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'WILO_POC_LookUp',\n",
       "   'version': '2',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'azureml-dataprep[pandas,fuse]',\n",
       "        'pyarrow==0.12.0',\n",
       "        'joblib==0.14.1',\n",
       "        'scikit-learn==0.20.3']},\n",
       "      'numpy==1.16.2'],\n",
       "     'name': 'azureml_42df74e95cf2de1f301b9fba9e8035c0'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'itpCompute': {'configuration': {}},\n",
       "  'cmAksCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.LookUpPrediction_1592829616_abf28b61/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=0yFA%2BDtNEp7PMwEGEh31s7sVCfMuoWPYexA6A3XqqJI%3D&st=2020-06-22T12%3A35%3A05Z&se=2020-06-22T20%3A45%3A05Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.LookUpPrediction_1592829616_abf28b61/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=LkEsIlB6lhaRR02JbmK%2BzFHZO6KMQ%2BGq%2FaUHoO2DCyo%3D&st=2020-06-22T12%3A35%3A05Z&se=2020-06-22T20%3A45%3A05Z&sp=r',\n",
       "  'logs/azureml/8_azureml.log': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.LookUpPrediction_1592829616_abf28b61/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=InV6gMM1Ef2UM76aDsEoZHUYzoWlPolwEo2WA3Xobdg%3D&st=2020-06-22T12%3A35%3A04Z&se=2020-06-22T20%3A45%3A04Z&sp=r'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = Experiment(ws, cfg['experiment_name'])\n",
    "run = exp.submit(est)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading artifacts/train_data.csv\n",
      "Uploaded artifacts/train_data.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', './LookUpPrediction')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"7b05e6a0-bdcb-4dac-badd-43da21ebfb81\",\n",
       "    \"name\": \"LookUpTrainData\",\n",
       "    \"version\": 1,\n",
       "    \"workspace\": \"Workspace.create(name='resdynml1test', subscription_id='793146d9-d4dc-4a73-9728-76c4ffd0cc0d', resource_group='rg_dynamics_test')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.download_file('outputs/train_data.csv', output_file_path='artifacts/train_data.csv')\n",
    "ds = ws.datastores[cfg['storage']]\n",
    "data_ref = ds.upload_files(['artifacts/train_data.csv'], target_path='./'+cfg['experiment_name'], overwrite=True)\n",
    "prepared_data_dataset = Dataset.Tabular.from_delimited_files(data_ref, separator=';', header=True, infer_column_types=True)\n",
    "prepared_data_dataset.register(ws, cfg['train_dataset'], create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading artifacts/test_data.csv\n",
      "Uploaded artifacts/test_data.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', './LookUpPrediction')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"1cf29584-c0d6-4a92-b14d-3bc8bcd83723\",\n",
       "    \"name\": \"LookUpTestData\",\n",
       "    \"version\": 1,\n",
       "    \"workspace\": \"Workspace.create(name='resdynml1test', subscription_id='793146d9-d4dc-4a73-9728-76c4ffd0cc0d', resource_group='rg_dynamics_test')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.download_file('outputs/test_data.csv', output_file_path='artifacts/test_data.csv')\n",
    "ds = ws.datastores[cfg['storage']]\n",
    "data_ref = ds.upload_files(['artifacts/test_data.csv'], target_path='./'+cfg['experiment_name'], overwrite=True)\n",
    "prepared_data_dataset = Dataset.Tabular.from_delimited_files(data_ref, separator=';', header=True, infer_column_types=False)\n",
    "prepared_data_dataset.register(ws, cfg['test_dataset'], create_new_version=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
