{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.train.estimator import Estimator\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"39288a38-ff19-432c-8011-1cd9d0dff445\")\n",
    "ws = Workspace(subscription_id=\"793146d9-d4dc-4a73-9728-76c4ffd0cc0d\", resource_group=\"rg_dynamics_test\", workspace_name=\"resdynml1test\", auth=interactive_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experiment cfg\n",
    "with open(\"experiment_cfg.json\", \"r\") as cfg_file:\n",
    "    cfg = json.load(cfg_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/lookup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/lookup.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class LookUpClassifier():\n",
    "    \n",
    "    def __init__(self, threshold=0.5):\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def fit(self, df):\n",
    "        \n",
    "        self.product_transform = list(set(x for l in df['ProductNrs'].apply(lambda x: x.split()).values.tolist() for x in l))\n",
    "        \n",
    "        symptoms_per_case_df = pd.DataFrame(df['Symptoms'].str.split(' ').tolist(), index=df['Job Card.JobCard Number']).stack().reset_index([0, 'Job Card.JobCard Number'])\n",
    "        symptoms_per_case_df.columns = ['Job Card.JobCard Number', 'Symptom']\n",
    "\n",
    "        prodnr_per_case_df = pd.DataFrame(df['ProductNrs'].str.split(' ').tolist(), index=df['Job Card.JobCard Number']).stack().reset_index([0, 'Job Card.JobCard Number'])\n",
    "        prodnr_per_case_df.columns = ['Job Card.JobCard Number', 'ProductNr']\n",
    "\n",
    "        df = pd.merge(symptoms_per_case_df, df, on='Job Card.JobCard Number', how='left')\n",
    "        df = pd.merge(prodnr_per_case_df, df, on='Job Card.JobCard Number', how='left')\n",
    "\n",
    "        df = df[['ProductId', 'Country', 'Symptom', 'ProductNr']].replace('', np.nan).dropna().reset_index(drop=True)\n",
    "\n",
    "#         self.model = df.groupby(['ProductId', 'Country', 'Symptom'])#\n",
    "        self.model = {}\n",
    "        for i in range(len(df)):\n",
    "            if not df['ProductId'][i] in self.model:\n",
    "                self.model[df['ProductId'][i]] = {}\n",
    "            if not df['Country'][i] in self.model[df['ProductId'][i]]:\n",
    "                self.model[df['ProductId'][i]][df['Country'][i]] = {}\n",
    "            if not df['Symptom'][i] in self.model[df['ProductId'][i]][df['Country'][i]]:\n",
    "                self.model[df['ProductId'][i]][df['Country'][i]][df['Symptom'][i]] = []\n",
    "            self.model[df['ProductId'][i]][df['Country'][i]][df['Symptom'][i]].append(df['ProductNr'][i])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # X = [['<prodid>', '<country>', '<symptom1>, <symptom2>']]\n",
    "        y = []\n",
    "        for row in X:\n",
    "            y_row = []\n",
    "            for symptom in row[2].split(' '):\n",
    "                if row[0] in self.model:\n",
    "                    if row[1] in self.model[row[0]]:\n",
    "                        if symptom in self.model[row[0]][row[1]]:\n",
    "                            y_row += self.model[row[0]][row[1]][symptom]\n",
    "            \n",
    "            y_probs = np.random.random(len(y_row))\n",
    "            y_row = [ y_row[i] for i in range(len(y_probs)) if y_probs[i] > self.threshold ]\n",
    "            \n",
    "            y.append(' '.join(map(str, list(set(y_row)))))\n",
    "            \n",
    "        return y\n",
    "    \n",
    "    def transform_products(self, y):\n",
    "        # y = [ '<prod1> <prod2>', '<prod1> <prod3>' ]\n",
    "        y_tr = np.zeros([len(y), len(self.product_transform)])\n",
    "        for row in range(len(y)):\n",
    "            for prod in y[row].split(' '):\n",
    "                if prod in self.product_transform:\n",
    "                    y_tr[row, self.product_transform.index(prod)] = 1\n",
    "        return y_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/train.py\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "from argparse import ArgumentParser\n",
    "from lookup import LookUpClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, hamming_loss, zero_one_loss, mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('--input', dest='prepared_data')\n",
    "args = parser.parse_args()\n",
    "\n",
    "############################################################\n",
    "\n",
    "print('\\n#####################################################')\n",
    "print('loaded')\n",
    "print('\\n#####################################################')\n",
    "\n",
    "# load data\n",
    "if args.prepared_data:\n",
    "    train_data = pd.read_csv(args.prepared_data + '/train_data.csv', sep=';', header=0)\n",
    "    test_data = pd.read_csv(args.prepared_data + '/test_data.csv', sep=';', header=0)\n",
    "else:\n",
    "    train_data = run.input_datasets['train_data'].to_pandas_dataframe()\n",
    "    test_data = run.input_datasets['test_data'].to_pandas_dataframe()\n",
    "    \n",
    "train_data = train_data.dropna().reset_index(drop=True)\n",
    "test_data = test_data.dropna().reset_index(drop=True)\n",
    "    \n",
    "#################################################################\n",
    "\n",
    "print('\\n#####################################################')\n",
    "print('train')\n",
    "print('\\n#####################################################')\n",
    "\n",
    "# train classifier\n",
    "model = LookUpClassifier(threshold=0.2)\n",
    "model.fit(train_data)\n",
    "\n",
    "print('\\n#####################################################')\n",
    "print('trained')\n",
    "print('\\n#####################################################')\n",
    "\n",
    "############################################################\n",
    "\n",
    "X_test = test_data[['ProductId', 'Country', 'Symptoms']].values.tolist()\n",
    "y_test = test_data['ProductNrs'].values.tolist() \n",
    "\n",
    "X_train = train_data[['ProductId', 'Country', 'Symptoms']].values.tolist()\n",
    "y_train = train_data['ProductNrs'].values.tolist() \n",
    "\n",
    "############################################################\n",
    "\n",
    "# # evaluate test data\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_pred_tr = model.transform_products(y_pred)\n",
    "# y_test_tr = model.transform_products(y_test)\n",
    "# run.log_table(\n",
    "#     'test_evaluation_classification',\n",
    "#     {\n",
    "#         'precision_macro': [precision_score(y_test_tr, y_pred_tr, average='macro')],\n",
    "#         'precision_samples': [precision_score(y_test_tr, y_pred_tr, average='samples')],\n",
    "#         'recall_macro': [recall_score(y_test_tr, y_pred_tr, average='macro')],\n",
    "#         'recall_samples': [recall_score(y_test_tr, y_pred_tr, average='samples')],\n",
    "#         'hamming_loss': [hamming_loss(y_test_tr, y_pred_tr)],\n",
    "#         'zero_one_loss': [zero_one_loss(y_test_tr, y_pred_tr)]\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # evaluate train data\n",
    "# y_pred = model.predict(X_train)\n",
    "# y_pred_tr = model.transform_products(y_pred)\n",
    "# y_train_tr = model.transform_products(y_train)\n",
    "# run.log_table(\n",
    "#     'train_evaluation_classification',\n",
    "#     {\n",
    "#         'precision_macro_train': [precision_score(y_train_tr, y_pred_tr, average='macro')],\n",
    "#         'precision_samples_train': [precision_score(y_train_tr, y_pred_tr, average='samples')],\n",
    "#         'recall_macro_train': [recall_score(y_train_tr, y_pred_tr, average='macro')],\n",
    "#         'recall_samples_train': [recall_score(y_train_tr, y_pred_tr, average='samples')],\n",
    "#         'hamming_loss_train': [hamming_loss(y_train_tr, y_pred_tr)],\n",
    "#         'zero_one_loss_train': [zero_one_loss(y_train_tr, y_pred_tr)]\n",
    "#     }\n",
    "# )\n",
    "\n",
    "############################################################\n",
    "\n",
    "# save model\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = Estimator(entry_script='train.py', source_directory='src',\n",
    "                inputs=[ws.datasets[cfg['train_dataset']].as_named_input('train_data'), \n",
    "                        ws.datasets[cfg['test_dataset']].as_named_input('test_data')   ],\n",
    "                compute_target=cfg['compute_target'], environment_definition=ws.environments[cfg['env_name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: LookUpPrediction_1592833657_8f12ad73\n",
      "Web View: https://ml.azure.com/experiments/LookUpPrediction/runs/LookUpPrediction_1592833657_8f12ad73?wsid=/subscriptions/793146d9-d4dc-4a73-9728-76c4ffd0cc0d/resourcegroups/rg_dynamics_test/workspaces/resdynml1test\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_068cdeb5d4e5a75752476994dc6ded2eda9f98d6faa2bebe1480cd2f2071660c_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2020-06-22T13:51:41Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2020-06-22T13:51:42Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "2020-06-22T13:51:42Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2020-06-22T13:51:42Z Starting output-watcher...\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_c14e68a5a54beac144cd751fe11b91c5\n",
      "a1298f4ce990: Pulling fs layer\n",
      "04a3282d9c4b: Pulling fs layer\n",
      "9b0d3db6dc03: Pulling fs layer\n",
      "8269c605f3f1: Pulling fs layer\n",
      "6504d449e70c: Pulling fs layer\n",
      "4e38f320d0d4: Pulling fs layer\n",
      "b0a763e8ee03: Pulling fs layer\n",
      "11917a028ca4: Pulling fs layer\n",
      "a6c378d11cbf: Pulling fs layer\n",
      "6cc007ad9140: Pulling fs layer\n",
      "6c1698a608f3: Pulling fs layer\n",
      "000aacc20dee: Pulling fs layer\n",
      "921e47b34d8d: Pulling fs layer\n",
      "79aa1f3566b6: Pulling fs layer\n",
      "114594c89ae1: Pulling fs layer\n",
      "1f700cc39777: Pulling fs layer\n",
      "6cf3cc306b86: Pulling fs layer\n",
      "6504d449e70c: Waiting\n",
      "4e38f320d0d4: Waiting\n",
      "b0a763e8ee03: Waiting\n",
      "11917a028ca4: Waiting\n",
      "8269c605f3f1: Waiting\n",
      "a6c378d11cbf: Waiting\n",
      "79aa1f3566b6: Waiting\n",
      "114594c89ae1: Waiting\n",
      "1f700cc39777: Waiting\n",
      "6cf3cc306b86: Waiting\n",
      "6cc007ad9140: Waiting\n",
      "6c1698a608f3: Waiting\n",
      "000aacc20dee: Waiting\n",
      "921e47b34d8d: Waiting\n",
      "9b0d3db6dc03: Verifying Checksum\n",
      "9b0d3db6dc03: Download complete\n",
      "04a3282d9c4b: Verifying Checksum\n",
      "04a3282d9c4b: Download complete\n",
      "a1298f4ce990: Verifying Checksum\n",
      "a1298f4ce990: Download complete\n",
      "8269c605f3f1: Verifying Checksum\n",
      "8269c605f3f1: Download complete\n",
      "6504d449e70c: Verifying Checksum\n",
      "6504d449e70c: Download complete\n",
      "4e38f320d0d4: Verifying Checksum\n",
      "4e38f320d0d4: Download complete\n",
      "11917a028ca4: Verifying Checksum\n",
      "11917a028ca4: Download complete\n",
      "b0a763e8ee03: Verifying Checksum\n",
      "b0a763e8ee03: Download complete\n",
      "a6c378d11cbf: Verifying Checksum\n",
      "a6c378d11cbf: Download complete\n",
      "6c1698a608f3: Verifying Checksum\n",
      "6c1698a608f3: Download complete\n",
      "6cc007ad9140: Verifying Checksum\n",
      "6cc007ad9140: Download complete\n",
      "000aacc20dee: Verifying Checksum\n",
      "000aacc20dee: Download complete\n",
      "114594c89ae1: Verifying Checksum\n",
      "114594c89ae1: Download complete\n",
      "921e47b34d8d: Verifying Checksum\n",
      "921e47b34d8d: Download complete\n",
      "79aa1f3566b6: Verifying Checksum\n",
      "79aa1f3566b6: Download complete\n",
      "a1298f4ce990: Pull complete\n",
      "04a3282d9c4b: Pull complete\n",
      "9b0d3db6dc03: Pull complete\n",
      "8269c605f3f1: Pull complete\n",
      "6cf3cc306b86: Verifying Checksum\n",
      "6cf3cc306b86: Download complete\n",
      "1f700cc39777: Verifying Checksum\n",
      "1f700cc39777: Download complete\n",
      "6504d449e70c: Pull complete\n",
      "4e38f320d0d4: Pull complete\n",
      "b0a763e8ee03: Pull complete\n",
      "11917a028ca4: Pull complete\n",
      "a6c378d11cbf: Pull complete\n",
      "6cc007ad9140: Pull complete\n",
      "6c1698a608f3: Pull complete\n",
      "000aacc20dee: Pull complete\n",
      "921e47b34d8d: Pull complete\n",
      "79aa1f3566b6: Pull complete\n",
      "114594c89ae1: Pull complete\n",
      "1f700cc39777: Pull complete\n",
      "6cf3cc306b86: Pull complete\n",
      "Digest: sha256:7599d0a6023b356a998541c47fbac5f1c5fa1703ab6a07da45ad6b75da1ee74d\n",
      "Status: Downloaded newer image for resdynml1tes2b0154b9.azurecr.io/azureml/azureml_c14e68a5a54beac144cd751fe11b91c5:latest\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_068cdeb5d4e5a75752476994dc6ded2eda9f98d6faa2bebe1480cd2f2071660c_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Entering job preparation. Current time:2020-06-22T13:52:47.700768\n",
      "Starting job preparation. Current time:2020-06-22T13:52:48.285787\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: b3813da0-0db5-4a3f-af4b-15fac9ee0fca\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 57\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "downloadDataStore - Download from datastores if requested.\n",
      "Entering context manager injector. Current time:2020-06-22T13:52:49.649432\n",
      "downloadDataStore completed\n",
      "Job preparation is complete. Current time:2020-06-22T13:52:50.363469\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Entering context manager injector. Current time:2020-06-22T13:52:51.401097\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 114\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ train.py ] with arguments: []\n",
      "After variable expansion, calling script [ train.py ] with arguments: []\n",
      "\n",
      "\n",
      "#####################################################\n",
      "loaded\n",
      "\n",
      "#####################################################\n",
      "\n",
      "#####################################################\n",
      "train\n",
      "\n",
      "#####################################################\n",
      "\n",
      "#####################################################\n",
      "trained\n",
      "\n",
      "#####################################################\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 114\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.21723628044128418 seconds\n",
      "2020/06/22 13:55:07 Process Exiting with Code:  0\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_068cdeb5d4e5a75752476994dc6ded2eda9f98d6faa2bebe1480cd2f2071660c_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Entering job release. Current time:2020-06-22T13:55:08.780884\n",
      "Starting job release. Current time:2020-06-22T13:55:09.734228\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 335\n",
      "Entering context manager injector. Current time:2020-06-22T13:55:09.753214\n",
      "Job release is complete. Current time:2020-06-22T13:55:11.576557\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: LookUpPrediction_1592833657_8f12ad73\n",
      "Web View: https://ml.azure.com/experiments/LookUpPrediction/runs/LookUpPrediction_1592833657_8f12ad73?wsid=/subscriptions/793146d9-d4dc-4a73-9728-76c4ffd0cc0d/resourcegroups/rg_dynamics_test/workspaces/resdynml1test\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'LookUpPrediction_1592833657_8f12ad73',\n",
       " 'target': 'mlcompute',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-06-22T13:51:37.814442Z',\n",
       " 'endTimeUtc': '2020-06-22T13:55:17.551748Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'bf1c23b4-a85d-4437-a8d0-e8ce41efda23',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '1cf29584-c0d6-4a92-b14d-3bc8bcd83723'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'test_data', 'mechanism': 'Direct'}}, {'dataset': {'id': '7b05e6a0-bdcb-4dac-badd-43da21ebfb81'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'train_data', 'mechanism': 'Direct'}}],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'mlcompute',\n",
       "  'dataReferences': {},\n",
       "  'data': {'test_data': {'dataLocation': {'dataset': {'id': '1cf29584-c0d6-4a92-b14d-3bc8bcd83723',\n",
       "      'name': None,\n",
       "      'version': None},\n",
       "     'dataPath': None},\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'test_data',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False},\n",
       "   'train_data': {'dataLocation': {'dataset': {'id': '7b05e6a0-bdcb-4dac-badd-43da21ebfb81',\n",
       "      'name': None,\n",
       "      'version': None},\n",
       "     'dataPath': None},\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'train_data',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'WILO_POC_LookUp',\n",
       "   'version': '2',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'azureml-dataprep[pandas,fuse]',\n",
       "        'pyarrow==0.12.0',\n",
       "        'joblib==0.14.1',\n",
       "        'scikit-learn==0.20.3']},\n",
       "      'numpy==1.16.2'],\n",
       "     'name': 'azureml_42df74e95cf2de1f301b9fba9e8035c0'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'itpCompute': {'configuration': {}},\n",
       "  'cmAksCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_068cdeb5d4e5a75752476994dc6ded2eda9f98d6faa2bebe1480cd2f2071660c_d.txt': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.LookUpPrediction_1592833657_8f12ad73/azureml-logs/55_azureml-execution-tvmps_068cdeb5d4e5a75752476994dc6ded2eda9f98d6faa2bebe1480cd2f2071660c_d.txt?sv=2019-02-02&sr=b&sig=5qb1lj634E%2FdOmuxYCQSIXf%2FP8X9oeIGtYXKS9o1fu0%3D&st=2020-06-22T13%3A45%3A18Z&se=2020-06-22T21%3A55%3A18Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_068cdeb5d4e5a75752476994dc6ded2eda9f98d6faa2bebe1480cd2f2071660c_d.txt': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.LookUpPrediction_1592833657_8f12ad73/azureml-logs/65_job_prep-tvmps_068cdeb5d4e5a75752476994dc6ded2eda9f98d6faa2bebe1480cd2f2071660c_d.txt?sv=2019-02-02&sr=b&sig=st3CoH2xIL9oALGR%2By4bXcjxTgxo5AWb2S8jbT%2BFURY%3D&st=2020-06-22T13%3A45%3A18Z&se=2020-06-22T21%3A55%3A18Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.LookUpPrediction_1592833657_8f12ad73/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=FLiGD4Q%2F5dGDBBPACwtgy3sPh%2FTYjn1im%2B90DtOqiU4%3D&st=2020-06-22T13%3A45%3A18Z&se=2020-06-22T21%3A55%3A18Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_068cdeb5d4e5a75752476994dc6ded2eda9f98d6faa2bebe1480cd2f2071660c_d.txt': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.LookUpPrediction_1592833657_8f12ad73/azureml-logs/75_job_post-tvmps_068cdeb5d4e5a75752476994dc6ded2eda9f98d6faa2bebe1480cd2f2071660c_d.txt?sv=2019-02-02&sr=b&sig=5kJ5ZhGtki18sTS%2BzIWRA7%2Bt%2FG1p9s7ouwfaOfXjOUE%3D&st=2020-06-22T13%3A45%3A18Z&se=2020-06-22T21%3A55%3A18Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.LookUpPrediction_1592833657_8f12ad73/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=%2BMogRqdFyif2%2FnnR9eRO6ICz%2FH9%2Fa3WHht3fU%2FWRPRA%3D&st=2020-06-22T13%3A45%3A18Z&se=2020-06-22T21%3A55%3A18Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.LookUpPrediction_1592833657_8f12ad73/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=1WiYXnu1VZPqtRqqqcrx09g%2BcxHg%2B89uIvaEZtHEMDM%3D&st=2020-06-22T13%3A45%3A18Z&se=2020-06-22T21%3A55%3A18Z&sp=r',\n",
       "  'logs/azureml/114_azureml.log': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.LookUpPrediction_1592833657_8f12ad73/logs/azureml/114_azureml.log?sv=2019-02-02&sr=b&sig=Dc22z4GgJjsNlwCk7EohbIjxJYltnP%2FAgU8T8i4qNBM%3D&st=2020-06-22T13%3A45%3A18Z&se=2020-06-22T21%3A55%3A18Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.LookUpPrediction_1592833657_8f12ad73/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=eiGYSOmDR8zcSEaHY%2FHAxx9%2Bpd0rXOVsAYmX%2BXUGuvI%3D&st=2020-06-22T13%3A45%3A18Z&se=2020-06-22T21%3A55%3A18Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.LookUpPrediction_1592833657_8f12ad73/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=1ay2Wd8kpThCqZPtQ1GNMaRZQQS%2Fhx4cFJismT6nT2E%3D&st=2020-06-22T13%3A45%3A18Z&se=2020-06-22T21%3A55%3A18Z&sp=r'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = Experiment(ws, cfg['experiment_name'])\n",
    "run = exp.submit(est)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='resdynml1test', subscription_id='793146d9-d4dc-4a73-9728-76c4ffd0cc0d', resource_group='rg_dynamics_test'), name=LookUpModel, id=LookUpModel:1, version=1, tags={}, properties={})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register trained model\n",
    "run.register_model(cfg['TrainedClassifier'], 'outputs/model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
