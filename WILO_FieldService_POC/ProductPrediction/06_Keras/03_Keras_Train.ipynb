{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.train.estimator import Estimator\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"39288a38-ff19-432c-8011-1cd9d0dff445\")\n",
    "ws = Workspace(subscription_id=\"793146d9-d4dc-4a73-9728-76c4ffd0cc0d\", resource_group=\"rg_dynamics_test\", workspace_name=\"resdynml1test\", auth=interactive_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experiment cfg\n",
    "with open(\"experiment_cfg.json\", \"r\") as cfg_file:\n",
    "    cfg = json.load(cfg_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./src/train.py\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.metrics import recall_score, precision_score, hamming_loss, zero_one_loss, mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('--input', dest='preprocessed_data')\n",
    "args = parser.parse_args()\n",
    "\n",
    "############################################################\n",
    "\n",
    "# load data\n",
    "if args.preprocessed_data:\n",
    "    train_data = pd.read_csv(args.preprocessed_data + '/train_data.csv', sep=';', header=0)\n",
    "    test_data = pd.read_csv(args.preprocessed_data + '/test_data.csv', sep=';', header=0)\n",
    "else:\n",
    "    train_data = run.input_datasets['train_data'].to_pandas_dataframe()\n",
    "    test_data = run.input_datasets['test_data'].to_pandas_dataframe()\n",
    "    \n",
    "############################################################\n",
    "\n",
    "# split train/test and feat/target\n",
    "X_train = train_data[[ col for col in train_data.columns if col.startswith('feat')]].values\n",
    "y_train = train_data[[ col for col in train_data.columns if col.startswith('target')]].drop(['target_0'], axis=1).values\n",
    "X_test = test_data[[col for col in test_data.columns if col.startswith('feat')]].values\n",
    "y_test = test_data[[ col for col in test_data.columns if col.startswith('target')]].drop(['target_0'], axis=1).values\n",
    "\n",
    "############################################################\n",
    "\n",
    "# create model\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "outputs = Dense(y_train.shape[1], activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "run.log('Model Summary', model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "# tf.keras.metrics.Recall(top_k=y_train.shape[1])\n",
    "\n",
    "# train classifier\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=10)\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# evaluate test data\n",
    "y_pred = model.predict(X_test).round()\n",
    "run.log_table(\n",
    "    'test_evaluation_classification',\n",
    "    {\n",
    "        'precision_macro': [precision_score(y_test, y_pred, average='macro')],\n",
    "        'precision_samples': [precision_score(y_test, y_pred, average='samples')],\n",
    "        'recall_macro': [recall_score(y_test, y_pred, average='macro')],\n",
    "        'recall_samples': [recall_score(y_test, y_pred, average='samples')],\n",
    "        'hamming_loss': [hamming_loss(y_test, y_pred)],\n",
    "        'zero_one_loss': [zero_one_loss(y_test, y_pred)]\n",
    "    }\n",
    ")\n",
    "\n",
    "# evaluate train data\n",
    "y_pred = model.predict(X_train).round()\n",
    "run.log_table(\n",
    "    'train_evaluation_classification',\n",
    "    {\n",
    "        'precision_macro_train': [precision_score(y_train, y_pred, average='macro')],\n",
    "        'precision_samples_train': [precision_score(y_train, y_pred, average='samples')],\n",
    "        'recall_macro_train': [recall_score(y_train, y_pred, average='macro')],\n",
    "        'recall_samples_train': [recall_score(y_train, y_pred, average='samples')],\n",
    "        'hamming_loss_train': [hamming_loss(y_train, y_pred)],\n",
    "        'zero_one_loss_train': [zero_one_loss(y_train, y_pred)]\n",
    "    }\n",
    ")\n",
    "\n",
    "# save model\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "#joblib.dump(value=model, filename='outputs/model.pkl')\n",
    "model.save('outputs/model.pkl')\n",
    "\n",
    "############################################################\n",
    "\n",
    "# train regressor\n",
    "X_train = train_data[[ col for col in train_data.columns if col.startswith('feat')]].values\n",
    "y_train = train_data[[ col for col in train_data.columns if col.startswith('target')]][['target_0']].values\n",
    "X_test = test_data[[col for col in test_data.columns if col.startswith('feat')]].values\n",
    "y_test = test_data[[ col for col in test_data.columns if col.startswith('target')]][['target_0']].values\n",
    "y_test = y_test.values[:,0]\n",
    "\n",
    "############################################################\n",
    "\n",
    "# create model\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "\n",
    "outputs = Dense(y_train.shape[1], activation='linear')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "run.log('Model Summary', model.summary())\n",
    "\n",
    "model.compile(loss='root_mean_squared_error', optimizer='adam', metrics=[\"mae\"])\n",
    "# tf.keras.metrics.Recall(top_k=y_train.shape[1])\n",
    "\n",
    "# train classifier\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=10)\n",
    "\n",
    "############################################################\n",
    "\n",
    "# evaluate test data\n",
    "y_pred = model_regressor.predict(X_test)\n",
    "run.log_table(\n",
    "    'test_evaluation_regression',\n",
    "    {\n",
    "        'mae': [mean_absolute_error(y_test, y_pred)],\n",
    "        'mse': [mean_squared_error(y_test, y_pred)],\n",
    "        'r2': [r2_score(y_test, y_pred)]\n",
    "    }\n",
    ")\n",
    "\n",
    "# evaluate train data\n",
    "y_pred = model_regressor.predict(X_train)\n",
    "run.log_table(\n",
    "    'train_evaluation_regression',\n",
    "    {\n",
    "        'mae_train': [mean_absolute_error(y_train, y_pred)],\n",
    "        'mse_train': [mean_squared_error(y_train, y_pred)],\n",
    "        'r2_train': [r2_score(y_train, y_train)]\n",
    "    }\n",
    ")\n",
    "\n",
    "############################################################\n",
    "\n",
    "# save regressor model\n",
    "# joblib.dump(value=model_regressor, filename='outputs/model_regressor.pkl')\n",
    "model.save('outputs/model_regressor.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est = TensorFlow(entry_script='train.py', source_directory='src',\n",
    "#              inputs=[    ws.datasets['DummyPredictionTrain'].as_named_input('train_data'), \n",
    "#                          ws.datasets['DummyPredictionTest'].as_named_input('test_data')],\n",
    "#              compute_target='local', pip_packages=['pyarrow==0.12.0', 'joblib'],\n",
    "#                  framework_version='2.0')#, environment_definition=ws.environments[env_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = Estimator(entry_script='train.py', source_directory='src',\n",
    "                inputs=[ws.datasets[cfg['train_dataset']].as_named_input('train_data'), \n",
    "                        ws.datasets[cfg['test_dataset']].as_named_input('test_data')   ],\n",
    "                compute_target=cfg['compute_target'], environment_definition=ws.environments[cfg['env_name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp = Experiment(ws, cfg['experiment_name'])\n",
    "run = exp.submit(est)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register trained model\n",
    "run.register_model(cfg['TrainedClassifier'], 'outputs/model.pkl')\n",
    "run.register_model(cfg['TrainedRegressor'], 'outputs/model_regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
