{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.train.estimator import Estimator\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"39288a38-ff19-432c-8011-1cd9d0dff445\")\n",
    "ws = Workspace(subscription_id=\"793146d9-d4dc-4a73-9728-76c4ffd0cc0d\", resource_group=\"rg_dynamics_test\", workspace_name=\"resdynml1test\", auth=interactive_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experiment cfg\n",
    "with open(\"experiment_cfg.json\", \"r\") as cfg_file:\n",
    "    cfg = json.load(cfg_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/train.py\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.metrics import recall_score, precision_score, hamming_loss, zero_one_loss, mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('--input', dest='preprocessed_data')\n",
    "args = parser.parse_args()\n",
    "\n",
    "############################################################\n",
    "\n",
    "# load data\n",
    "if args.preprocessed_data:\n",
    "    train_data = pd.read_csv(args.preprocessed_data + '/train_data.csv', sep=';', header=0)\n",
    "    test_data = pd.read_csv(args.preprocessed_data + '/test_data.csv', sep=';', header=0)\n",
    "else:\n",
    "    train_data = run.input_datasets['train_data'].to_pandas_dataframe()\n",
    "    test_data = run.input_datasets['test_data'].to_pandas_dataframe()\n",
    "    \n",
    "############################################################\n",
    "\n",
    "# split train/test and feat/target\n",
    "X_train = train_data[[ col for col in train_data.columns if col.startswith('feat')]].values\n",
    "y_train = train_data[[ col for col in train_data.columns if col.startswith('target')]].drop(['target_0'], axis=1).values\n",
    "X_test = test_data[[col for col in test_data.columns if col.startswith('feat')]].values\n",
    "y_test = test_data[[ col for col in test_data.columns if col.startswith('target')]].drop(['target_0'], axis=1).values\n",
    "\n",
    "############################################################\n",
    "\n",
    "# create model\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(128, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "outputs = Dense(y_train.shape[1], activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "run.log('Model Summary', model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "# tf.keras.metrics.Recall(top_k=y_train.shape[1])\n",
    "\n",
    "# train classifier\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=10)\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# evaluate test data\n",
    "y_pred = model.predict(X_test).round()\n",
    "run.log_table(\n",
    "    'test_evaluation_classification',\n",
    "    {\n",
    "        'precision_macro': [precision_score(y_test, y_pred, average='macro')],\n",
    "        'precision_samples': [precision_score(y_test, y_pred, average='samples')],\n",
    "        'recall_macro': [recall_score(y_test, y_pred, average='macro')],\n",
    "        'recall_samples': [recall_score(y_test, y_pred, average='samples')],\n",
    "        'hamming_loss': [hamming_loss(y_test, y_pred)],\n",
    "        'zero_one_loss': [zero_one_loss(y_test, y_pred)]\n",
    "    }\n",
    ")\n",
    "\n",
    "# evaluate train data\n",
    "y_pred = model.predict(X_train).round()\n",
    "run.log_table(\n",
    "    'train_evaluation_classification',\n",
    "    {\n",
    "        'precision_macro_train': [precision_score(y_train, y_pred, average='macro')],\n",
    "        'precision_samples_train': [precision_score(y_train, y_pred, average='samples')],\n",
    "        'recall_macro_train': [recall_score(y_train, y_pred, average='macro')],\n",
    "        'recall_samples_train': [recall_score(y_train, y_pred, average='samples')],\n",
    "        'hamming_loss_train': [hamming_loss(y_train, y_pred)],\n",
    "        'zero_one_loss_train': [zero_one_loss(y_train, y_pred)]\n",
    "    }\n",
    ")\n",
    "\n",
    "# save model\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "#joblib.dump(value=model, filename='outputs/model.pkl')\n",
    "model.save('outputs/model.pkl')\n",
    "\n",
    "############################################################\n",
    "\n",
    "# train regressor\n",
    "X_train = train_data[[ col for col in train_data.columns if col.startswith('feat')]].values\n",
    "y_train = train_data[[ col for col in train_data.columns if col.startswith('target')]][['target_0']].values\n",
    "X_test = test_data[[col for col in test_data.columns if col.startswith('feat')]].values\n",
    "y_test = test_data[[ col for col in test_data.columns if col.startswith('target')]][['target_0']].values\n",
    "y_test = y_test.values[:,0]\n",
    "\n",
    "############################################################\n",
    "\n",
    "# create model\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x = Dense(128, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "outputs = Dense(y_train.shape[1], activation='linear')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "run.log('Model Summary', model.summary())\n",
    "\n",
    "model.compile(loss='root_mean_squared_error', optimizer='adam', metrics=[\"mae\"])\n",
    "# tf.keras.metrics.Recall(top_k=y_train.shape[1])\n",
    "\n",
    "# train classifier\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=10)\n",
    "\n",
    "############################################################\n",
    "\n",
    "# evaluate test data\n",
    "y_pred = model_regressor.predict(X_test)\n",
    "run.log_table(\n",
    "    'test_evaluation_regression',\n",
    "    {\n",
    "        'mae': [mean_absolute_error(y_test, y_pred)],\n",
    "        'mse': [mean_squared_error(y_test, y_pred)],\n",
    "        'r2': [r2_score(y_test, y_pred)]\n",
    "    }\n",
    ")\n",
    "\n",
    "# evaluate train data\n",
    "y_pred = model_regressor.predict(X_train)\n",
    "run.log_table(\n",
    "    'train_evaluation_regression',\n",
    "    {\n",
    "        'mae_train': [mean_absolute_error(y_train, y_pred)],\n",
    "        'mse_train': [mean_squared_error(y_train, y_pred)],\n",
    "        'r2_train': [r2_score(y_train, y_train)]\n",
    "    }\n",
    ")\n",
    "\n",
    "############################################################\n",
    "\n",
    "# save regressor model\n",
    "# joblib.dump(value=model_regressor, filename='outputs/model_regressor.pkl')\n",
    "model.save('outputs/model_regressor.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est = TensorFlow(entry_script='train.py', source_directory='src',\n",
    "#              inputs=[    ws.datasets['DummyPredictionTrain'].as_named_input('train_data'), \n",
    "#                          ws.datasets['DummyPredictionTest'].as_named_input('test_data')],\n",
    "#              compute_target='local', pip_packages=['pyarrow==0.12.0', 'joblib'],\n",
    "#                  framework_version='2.0')#, environment_definition=ws.environments[env_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = Estimator(entry_script='train.py', source_directory='src',\n",
    "                inputs=[ws.datasets[cfg['train_dataset']].as_named_input('train_data'), \n",
    "                        ws.datasets[cfg['test_dataset']].as_named_input('test_data')   ],\n",
    "                compute_target='local', environment_definition=ws.environments[cfg['env_name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: KerasPrediction_1592470984_42b9f8cc\n",
      "Web View: https://ml.azure.com/experiments/KerasPrediction/runs/KerasPrediction_1592470984_42b9f8cc?wsid=/subscriptions/793146d9-d4dc-4a73-9728-76c4ffd0cc0d/resourcegroups/rg_dynamics_test/workspaces/resdynml1test\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Entering context manager injector. Current time:2020-06-18T09:03:07.187771\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 31195\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ train.py ] with arguments: []\n",
      "After variable expansion, calling script [ train.py ] with arguments: []\n",
      "\n",
      "2020-06-18 09:06:32.318121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2020-06-18 09:06:32.324187: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2095195000 Hz\n",
      "2020-06-18 09:06:32.325193: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56111c5a7230 executing computations on platform Host. Devices:\n",
      "2020-06-18 09:06:32.325224: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 21)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               2816      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1430)              47190     \n",
      "=================================================================\n",
      "Total params: 60,342\n",
      "Trainable params: 60,342\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 12209 samples\n",
      "Epoch 1/10\n",
      "\n",
      "   64/12209 [..............................] - ETA: 1:58 - loss: 0.6934 - accuracy: 0.50\n",
      "  896/12209 [=>............................] - ETA: 8s - loss: 0.6833 - accuracy: 0.7882\n",
      " 1728/12209 [===>..........................] - ETA: 4s - loss: 0.6519 - accuracy: 0.88\n",
      " 2560/12209 [=====>........................] - ETA: 2s - loss: 0.5660 - accuracy: 0.92\n",
      " 3328/12209 [=======>......................] - ETA: 2s - loss: 0.4572 - accuracy: 0.93\n",
      " 4224/12209 [=========>....................] - ETA: 1s - loss: 0.3632 - accuracy: 0.9516\n",
      " 5056/12209 [===========>..................] - ETA: 1s - loss: 0.3048 - accuracy: 0.95\n",
      " 5952/12209 [=============>................] - ETA: 1s - loss: 0.2600 - accuracy: 0.96\n",
      " 6784/12209 [===============>..............] - ETA: 0s - loss: 0.2290 - accuracy: 0.96\n",
      " 7680/12209 [=================>............] - ETA: 0s - loss: 0.2031 - accuracy: 0.97\n",
      " 8640/12209 [====================>.........] - ETA: 0s - loss: 0.1813 - accuracy: 0.97\n",
      " 9472/12209 [======================>.......] - ETA: 0s - loss: 0.1660 - accuracy: 0.97\n",
      "10368/12209 [========================>.....] - ETA: 0s - loss: 0.1522 - accuracy: 0.97\n",
      "11328/12209 [==========================>...] - ETA: 0s - loss: 0.1399 - accuracy: 0.98\n",
      "12209/12209 [==============================] - 1s 111us/sample - loss: 0.1303 - accuracy: 0.9822\n",
      "Epoch 2/10\n",
      "\n",
      "   64/12209 [..............................] - ETA: 0s - loss: 0.0060 - accuracy: 0.99\n",
      "  960/12209 [=>............................] - ETA: 0s - loss: 0.0066 - accuracy: 0.99\n",
      " 1856/12209 [===>..........................] - ETA: 0s - loss: 0.0064 - accuracy: 0.99\n",
      " 2752/12209 [=====>........................] - ETA: 0s - loss: 0.0063 - accuracy: 0.99\n",
      " 3648/12209 [=======>......................] - ETA: 0s - loss: 0.0063 - accuracy: 0.99\n",
      " 4608/12209 [==========>...................] - ETA: 0s - loss: 0.0063 - accuracy: 0.99\n",
      " 5504/12209 [============>.................] - ETA: 0s - loss: 0.0063 - accuracy: 0.99\n",
      " 6464/12209 [==============>...............] - ETA: 0s - loss: 0.0063 - accuracy: 0.99\n",
      " 7360/12209 [=================>............] - ETA: 0s - loss: 0.0063 - accuracy: 0.99\n",
      " 8256/12209 [===================>..........] - ETA: 0s - loss: 0.0063 - accuracy: 0.99\n",
      " 9152/12209 [=====================>........] - ETA: 0s - loss: 0.0062 - accuracy: 0.99\n",
      "10048/12209 [=======================>......] - ETA: 0s - loss: 0.0062 - accuracy: 0.99\n",
      "10944/12209 [=========================>....] - ETA: 0s - loss: 0.0062 - accuracy: 0.99\n",
      "11904/12209 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.99\n",
      "12209/12209 [==============================] - 1s 57us/sample - loss: 0.0062 - accuracy: 0.9985\n",
      "Epoch 3/10\n",
      "\n",
      "   64/12209 [..............................] - ETA: 0s - loss: 0.0060 - accuracy: 0.99\n",
      " 1024/12209 [=>............................] - ETA: 0s - loss: 0.0058 - accuracy: 0.99\n",
      " 1920/12209 [===>..........................] - ETA: 0s - loss: 0.0059 - accuracy: 0.99\n",
      " 2752/12209 [=====>........................] - ETA: 0s - loss: 0.0060 - accuracy: 0.99\n",
      " 3648/12209 [=======>......................] - ETA: 0s - loss: 0.0059 - accuracy: 0.99\n",
      " 4480/12209 [==========>...................] - ETA: 0s - loss: 0.0058 - accuracy: 0.99\n",
      " 5440/12209 [============>.................] - ETA: 0s - loss: 0.0058 - accuracy: 0.99\n",
      " 6336/12209 [==============>...............] - ETA: 0s - loss: 0.0057 - accuracy: 0.99\n",
      " 7168/12209 [================>.............] - ETA: 0s - loss: 0.0057 - accuracy: 0.99\n",
      " 8064/12209 [==================>...........] - ETA: 0s - loss: 0.0057 - accuracy: 0.99\n",
      " 9024/12209 [=====================>........] - ETA: 0s - loss: 0.0056 - accuracy: 0.99\n",
      " 9920/12209 [=======================>......] - ETA: 0s - loss: 0.0056 - accuracy: 0.99\n",
      "10816/12209 [=========================>....] - ETA: 0s - loss: 0.0056 - accuracy: 0.99\n",
      "11712/12209 [===========================>..] - ETA: 0s - loss: 0.0055 - accuracy: 0.99\n",
      "12209/12209 [==============================] - 1s 58us/sample - loss: 0.0055 - accuracy: 0.9987\n",
      "Epoch 4/10\n",
      "\n",
      "   64/12209 [..............................] - ETA: 0s - loss: 0.0071 - accuracy: 0.99\n",
      "  960/12209 [=>............................] - ETA: 0s - loss: 0.0054 - accuracy: 0.99\n",
      " 1856/12209 [===>..........................] - ETA: 0s - loss: 0.0053 - accuracy: 0.99\n",
      " 2816/12209 [=====>........................] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      " 3776/12209 [========>.....................] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      " 4736/12209 [==========>...................] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      " 5632/12209 [============>.................] - ETA: 0s - loss: 0.0052 - accuracy: 0.9988\n",
      " 6464/12209 [==============>...............] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      " 7296/12209 [================>.............] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 8192/12209 [===================>..........] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      " 9088/12209 [=====================>........] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      " 9920/12209 [=======================>......] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      "10880/12209 [=========================>....] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      "11776/12209 [===========================>..] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      "12209/12209 [==============================] - 1s 58us/sample - loss: 0.0052 - accuracy: 0.9988\n",
      "Epoch 5/10\n",
      "\n",
      "   64/12209 [..............................] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      "  960/12209 [=>............................] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 1856/12209 [===>..........................] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      " 2624/12209 [=====>........................] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      " 3520/12209 [=======>......................] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      " 4480/12209 [==========>...................] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      " 5376/12209 [============>.................] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      " 6272/12209 [==============>...............] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 7168/12209 [================>.............] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 8064/12209 [==================>...........] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 8960/12209 [=====================>........] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 9856/12209 [=======================>......] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      "10752/12209 [=========================>....] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      "11584/12209 [===========================>..] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      "12209/12209 [==============================] - 1s 58us/sample - loss: 0.0051 - accuracy: 0.9988\n",
      "Epoch 6/10\n",
      "\n",
      "   64/12209 [..............................] - ETA: 0s - loss: 0.0056 - accuracy: 0.99\n",
      "  960/12209 [=>............................] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 1856/12209 [===>..........................] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 2752/12209 [=====>........................] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 3712/12209 [========>.....................] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 4608/12209 [==========>...................] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 5568/12209 [============>.................] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 6464/12209 [==============>...............] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 7360/12209 [=================>............] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 8128/12209 [==================>...........] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 9024/12209 [=====================>........] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 9920/12209 [=======================>......] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      "10752/12209 [=========================>....] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      "11648/12209 [===========================>..] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      "12209/12209 [==============================] - 1s 58us/sample - loss: 0.0051 - accuracy: 0.9988\n",
      "Epoch 7/10\n",
      "\n",
      "   64/12209 [..............................] - ETA: 0s - loss: 0.0048 - accuracy: 0.99\n",
      "  960/12209 [=>............................] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 1856/12209 [===>..........................] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 2816/12209 [=====>........................] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 3712/12209 [========>.....................] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 4672/12209 [==========>...................] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 5632/12209 [============>.................] - ETA: 0s - loss: 0.0050 - accuracy: 0.9988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6528/12209 [===============>..............] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 7424/12209 [=================>............] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 8320/12209 [===================>..........] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 9216/12209 [=====================>........] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      "10176/12209 [========================>.....] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      "10944/12209 [=========================>....] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      "11712/12209 [===========================>..] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      "12209/12209 [==============================] - 1s 58us/sample - loss: 0.0051 - accuracy: 0.9988\n",
      "Epoch 8/10\n",
      "\n",
      "   64/12209 [..............................] - ETA: 0s - loss: 0.0041 - accuracy: 0.99\n",
      "  896/12209 [=>............................] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      " 1792/12209 [===>..........................] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 2688/12209 [=====>........................] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 3520/12209 [=======>......................] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 4288/12209 [=========>....................] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 5184/12209 [===========>..................] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 6080/12209 [=============>................] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 6976/12209 [================>.............] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 7872/12209 [==================>...........] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 8768/12209 [====================>.........] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 9664/12209 [======================>.......] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      "10624/12209 [=========================>....] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      "11520/12209 [===========================>..] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      "12209/12209 [==============================] - 1s 58us/sample - loss: 0.0050 - accuracy: 0.9988\n",
      "Epoch 9/10\n",
      "\n",
      "   64/12209 [..............................] - ETA: 0s - loss: 0.0057 - accuracy: 0.99\n",
      "  960/12209 [=>............................] - ETA: 0s - loss: 0.0053 - accuracy: 0.99\n",
      " 1856/12209 [===>..........................] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 2752/12209 [=====>........................] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 3648/12209 [=======>......................] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 4544/12209 [==========>...................] - ETA: 0s - loss: 0.0052 - accuracy: 0.99\n",
      " 5440/12209 [============>.................] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 6400/12209 [==============>...............] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 7296/12209 [================>.............] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 8192/12209 [===================>..........] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 9152/12209 [=====================>........] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      "10048/12209 [=======================>......] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      "10944/12209 [=========================>....] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      "11840/12209 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      "12209/12209 [==============================] - 1s 57us/sample - loss: 0.0050 - accuracy: 0.9988\n",
      "Epoch 10/10\n",
      "\n",
      "   64/12209 [..............................] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      "  896/12209 [=>............................] - ETA: 0s - loss: 0.0049 - accuracy: 0.99\n",
      " 1664/12209 [===>..........................] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 2496/12209 [=====>........................] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 3392/12209 [=======>......................] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 4288/12209 [=========>....................] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 5184/12209 [===========>..................] - ETA: 0s - loss: 0.0051 - accuracy: 0.99\n",
      " 6016/12209 [=============>................] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 6912/12209 [===============>..............] - ETA: 0s - loss: 0.0050 - accuracy: 0.9988\n",
      " 7680/12209 [=================>............] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 8576/12209 [====================>.........] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      " 9472/12209 [======================>.......] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      "10368/12209 [========================>.....] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      "11264/12209 [==========================>...] - ETA: 0s - loss: 0.0050 - accuracy: 0.99\n",
      "12209/12209 [==============================] - 1s 60us/sample - loss: 0.0050 - accuracy: 0.9988\n",
      "2020-06-18 09:06:40.732965: W tensorflow/python/util/util.cc:299] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /home/azureuser/.azureml/envs/azureml_11a74f652b38787cd8ba913cc91d6de1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING - From /home/azureuser/.azureml/envs/azureml_11a74f652b38787cd8ba913cc91d6de1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 31195\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service.\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.2170546054840088 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: KerasPrediction_1592470984_42b9f8cc\n",
      "Web View: https://ml.azure.com/experiments/KerasPrediction/runs/KerasPrediction_1592470984_42b9f8cc?wsid=/subscriptions/793146d9-d4dc-4a73-9728-76c4ffd0cc0d/resourcegroups/rg_dynamics_test/workspaces/resdynml1test\n",
      "\n",
      "Warnings:\n",
      "Failed to post metric due to validation failure\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'KerasPrediction_1592470984_42b9f8cc',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-06-18T09:03:06.417289Z',\n",
       " 'endTimeUtc': '2020-06-18T09:06:44.465605Z',\n",
       " 'warnings': [{'source': 'RunHistoryService',\n",
       "   'message': 'Failed to post metric due to validation failure'}],\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '01764806-3d89-438d-b819-e6e1413b8c22'},\n",
       " 'inputDatasets': [{'dataset': {'id': 'b217579b-16ba-4c90-9e95-1776ba592742'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'test_data', 'mechanism': 'Direct'}}, {'dataset': {'id': '723a8324-8b50-48ba-9398-53c659959f56'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'train_data', 'mechanism': 'Direct'}}],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'test_data': {'dataLocation': {'dataset': {'id': 'b217579b-16ba-4c90-9e95-1776ba592742',\n",
       "      'name': None,\n",
       "      'version': None},\n",
       "     'dataPath': None},\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'test_data',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False},\n",
       "   'train_data': {'dataLocation': {'dataset': {'id': '723a8324-8b50-48ba-9398-53c659959f56',\n",
       "      'name': None,\n",
       "      'version': None},\n",
       "     'dataPath': None},\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'train_data',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'WILO_POC_keras',\n",
       "   'version': '4',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['tensorflow==2.0.0',\n",
       "        'azureml-defaults',\n",
       "        'pyarrow==0.12.0',\n",
       "        'joblib',\n",
       "        'azureml-dataprep[pandas,fuse]',\n",
       "        'scikit-learn==0.23.1']},\n",
       "      'numpy==1.18.1'],\n",
       "     'name': 'azureml_11a74f652b38787cd8ba913cc91d6de1'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'itpCompute': {'configuration': {}},\n",
       "  'cmAksCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.KerasPrediction_1592470984_42b9f8cc/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=kPmRt2BXq2m8T3PdlfFOwldneiLmHQQSmKNMpEwD0jA%3D&st=2020-06-18T08%3A56%3A45Z&se=2020-06-18T17%3A06%3A45Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.KerasPrediction_1592470984_42b9f8cc/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=vOAjm%2F9Yb00CBkMg4iBirFhZpxyYLg%2B6%2BYejOJVFHWU%3D&st=2020-06-18T08%3A56%3A45Z&se=2020-06-18T17%3A06%3A45Z&sp=r',\n",
       "  'logs/azureml/31195_azureml.log': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.KerasPrediction_1592470984_42b9f8cc/logs/azureml/31195_azureml.log?sv=2019-02-02&sr=b&sig=nccoHQu44IuD0SLvQz073ILm87fBlowwFRNdSZ8cEUM%3D&st=2020-06-18T08%3A56%3A45Z&se=2020-06-18T17%3A06%3A45Z&sp=r'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = Experiment(ws, cfg['experiment_name'])\n",
    "run = exp.submit(est)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register trained model\n",
    "run.register_model(cfg['TrainedClassifier'], 'outputs/model.pkl')\n",
    "run.register_model(cfg['TrainedRegressor'], 'outputs/model_regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
