{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Environment, Dataset\n",
    "from azureml.data.dataset_factory import DataType\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.train.estimator import Estimator\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"39288a38-ff19-432c-8011-1cd9d0dff445\")\n",
    "ws = Workspace(subscription_id=\"793146d9-d4dc-4a73-9728-76c4ffd0cc0d\", resource_group=\"rg_dynamics_test\", workspace_name=\"resdynml1test\", auth=interactive_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experiment cfg\n",
    "with open(\"experiment_cfg.json\", \"r\") as cfg_file:\n",
    "    cfg = json.load(cfg_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/prepare.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/prepare.py\n",
    "\n",
    "from azureml.core import Run\n",
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('--output', dest='prepared_data')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# load datasets\n",
    "df_symptoms = run.input_datasets['symptomcodes'].to_pandas_dataframe()\n",
    "df = run.input_datasets['df_raw'].to_pandas_dataframe()\n",
    "\n",
    "###########################################################\n",
    "\n",
    "# get only data from last t years\n",
    "t = 5\n",
    "df = df[df['Job Card.Date Start Work']>(datetime.datetime.today() - datetime.timedelta(days=t*365))]\n",
    "\n",
    "############################################################\n",
    "\n",
    "# clean data\n",
    "df = df.replace(['', '0', '-', '000','N/A'], np.nan)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "# combine Component/Failure Code in train data\n",
    "df = pd.concat([df, pd.DataFrame(df.apply(lambda x: (x['Job Card.ComponentCode'],x['Job Card.FailureCode']), axis=1), columns=['CompFail'])], axis=1)\n",
    "\n",
    "# combine Component/Failure Code in symptom table\n",
    "df_symptoms = df_symptoms[['ComponentCode', 'FailureCode', 'Symptom1', 'Symptom2', 'Symptom3', 'Symptom4']]\n",
    "df_symptoms = pd.concat([df_symptoms, pd.DataFrame(df_symptoms.apply(lambda x: (x['ComponentCode'],x['FailureCode']),axis=1), columns=['CompFail'])],axis=1)\n",
    "\n",
    "# merge train data on symptoms\n",
    "df = pd.merge(df, df_symptoms, on='CompFail', how='left')\n",
    "df = pd.concat([df, pd.DataFrame(df[['Symptom1', 'Symptom2', 'Symptom3', 'Symptom4']].apply(lambda x: tuple([ x[col] for col in ['Symptom1','Symptom2','Symptom3','Symptom4'] if str(x[col]) != 'None' ]), axis=1), columns=['Symptoms'])], axis=1)\n",
    "\n",
    "# remove rows with no symptoms\n",
    "df = df[df['Symptoms']!=()]\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# merge into one row per case\n",
    "df = df.groupby('Job Card.JobCard Number').apply(lambda x: pd.Series({\n",
    "    'ProductId': ' '.join(x['Installed Base.InstalledBase ProductID'].unique()),\n",
    "    'Country': ' '.join(x['Location.Country'].unique()),\n",
    "    'City': ' '.join(x['Location.City'].unique()),\n",
    "    'LocationType': ' '.join(x['Location.Location Type'].unique()),\n",
    "    'PostalCode': ' '.join(x['Location.Postal Code'].unique()),\n",
    "    'Symptoms': ' '.join(map(str, list(set(x['Symptoms'].sum())))),\n",
    "    'ProductNr': ' '.join(x['Product.Product Number'].unique()),\n",
    "    'Start': x['Job Card.Date Start Work'].min(),\n",
    "    'End': x['Job Card.Date End Work'].max(),\n",
    "    'Month': str(x['Job Card.Date Start Work'].min().month),\n",
    "    'Daytime': str(x['Job Card.Date Start Work'].min().hour),\n",
    "    'Weekday': str(x['Job Card.Date Start Work'].min().weekday())\n",
    "#     'duration': (x['Job Card.Date End Work']-x['Job Card.Date Start Work'])/3600\n",
    "  })).reset_index()\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# compute duration column\n",
    "df = pd.concat([df, pd.DataFrame((df['End'] - df['Start']), columns=['duration'])],axis=1)\n",
    "df['duration'] = df['duration'].apply(lambda x: x.seconds / 3600)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# save train and test data\n",
    "path = arg.prepared_data if args.prepared_data else './outputs'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "df.to_csv(path + '/prepared_data.csv', sep=';', header=True, index=False)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = Estimator(entry_script='prepare.py', source_directory='src', \n",
    "              inputs=[   ws.datasets[cfg['symptomcodes_dataset']].as_named_input('symptomcodes'), \n",
    "                         ws.datasets[cfg['raw_data_dataset']].as_named_input('df_raw')       ],\n",
    "              compute_target=cfg['compute_target'], environment_definition=ws.environments[cfg['env_name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: KerasPrediction_1592895405_905719ed\n",
      "Web View: https://ml.azure.com/experiments/KerasPrediction/runs/KerasPrediction_1592895405_905719ed?wsid=/subscriptions/793146d9-d4dc-4a73-9728-76c4ffd0cc0d/resourcegroups/rg_dynamics_test/workspaces/resdynml1test\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_8670620c0c73952bf6a4abf9aa164b0d774f783ac03bcc0b47e0643edd436355_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2020-06-23T07:00:43Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2020-06-23T07:00:43Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "2020-06-23T07:00:43Z Starting output-watcher...\n",
      "2020-06-23T07:00:43Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_c14e68a5a54beac144cd751fe11b91c5\n",
      "a1298f4ce990: Pulling fs layer\n",
      "04a3282d9c4b: Pulling fs layer\n",
      "9b0d3db6dc03: Pulling fs layer\n",
      "8269c605f3f1: Pulling fs layer\n",
      "6504d449e70c: Pulling fs layer\n",
      "4e38f320d0d4: Pulling fs layer\n",
      "b0a763e8ee03: Pulling fs layer\n",
      "11917a028ca4: Pulling fs layer\n",
      "a6c378d11cbf: Pulling fs layer\n",
      "6cc007ad9140: Pulling fs layer\n",
      "6c1698a608f3: Pulling fs layer\n",
      "000aacc20dee: Pulling fs layer\n",
      "921e47b34d8d: Pulling fs layer\n",
      "79aa1f3566b6: Pulling fs layer\n",
      "114594c89ae1: Pulling fs layer\n",
      "1f700cc39777: Pulling fs layer\n",
      "6cf3cc306b86: Pulling fs layer\n",
      "6cc007ad9140: Waiting\n",
      "6c1698a608f3: Waiting\n",
      "000aacc20dee: Waiting\n",
      "921e47b34d8d: Waiting\n",
      "79aa1f3566b6: Waiting\n",
      "114594c89ae1: Waiting\n",
      "1f700cc39777: Waiting\n",
      "6cf3cc306b86: Waiting\n",
      "4e38f320d0d4: Waiting\n",
      "b0a763e8ee03: Waiting\n",
      "11917a028ca4: Waiting\n",
      "a6c378d11cbf: Waiting\n",
      "8269c605f3f1: Waiting\n",
      "6504d449e70c: Waiting\n",
      "04a3282d9c4b: Verifying Checksum\n",
      "04a3282d9c4b: Download complete\n",
      "9b0d3db6dc03: Verifying Checksum\n",
      "9b0d3db6dc03: Download complete\n",
      "a1298f4ce990: Download complete\n",
      "8269c605f3f1: Verifying Checksum\n",
      "4e38f320d0d4: Verifying Checksum\n",
      "4e38f320d0d4: Download complete\n",
      "6504d449e70c: Verifying Checksum\n",
      "6504d449e70c: Download complete\n",
      "b0a763e8ee03: Verifying Checksum\n",
      "b0a763e8ee03: Download complete\n",
      "6cc007ad9140: Verifying Checksum\n",
      "6cc007ad9140: Download complete\n",
      "11917a028ca4: Verifying Checksum\n",
      "11917a028ca4: Download complete\n",
      "a6c378d11cbf: Verifying Checksum\n",
      "a6c378d11cbf: Download complete\n",
      "921e47b34d8d: Verifying Checksum\n",
      "921e47b34d8d: Download complete\n",
      "6c1698a608f3: Download complete\n",
      "000aacc20dee: Verifying Checksum\n",
      "000aacc20dee: Download complete\n",
      "79aa1f3566b6: Verifying Checksum\n",
      "79aa1f3566b6: Download complete\n",
      "a1298f4ce990: Pull complete\n",
      "6cf3cc306b86: Verifying Checksum\n",
      "6cf3cc306b86: Download complete\n",
      "04a3282d9c4b: Pull complete\n",
      "114594c89ae1: Verifying Checksum\n",
      "114594c89ae1: Download complete\n",
      "9b0d3db6dc03: Pull complete\n",
      "8269c605f3f1: Pull complete\n",
      "1f700cc39777: Verifying Checksum\n",
      "1f700cc39777: Download complete\n",
      "6504d449e70c: Pull complete\n",
      "4e38f320d0d4: Pull complete\n",
      "b0a763e8ee03: Pull complete\n",
      "11917a028ca4: Pull complete\n",
      "a6c378d11cbf: Pull complete\n",
      "6cc007ad9140: Pull complete\n",
      "6c1698a608f3: Pull complete\n",
      "000aacc20dee: Pull complete\n",
      "921e47b34d8d: Pull complete\n",
      "79aa1f3566b6: Pull complete\n",
      "114594c89ae1: Pull complete\n",
      "1f700cc39777: Pull complete\n",
      "6cf3cc306b86: Pull complete\n",
      "Digest: sha256:7599d0a6023b356a998541c47fbac5f1c5fa1703ab6a07da45ad6b75da1ee74d\n",
      "Status: Downloaded newer image for resdynml1tes2b0154b9.azurecr.io/azureml/azureml_c14e68a5a54beac144cd751fe11b91c5:latest\n",
      "4ba48f13dd8704bb68e3a7706dc2d94ec3a355e6ea341981d279477530986636\n",
      "2020/06/23 07:01:45 Starting App Insight Logger for task:  containerSetup\n",
      "2020/06/23 07:01:45 Version: 3.0.01251.0001 Branch: master Commit: 31ab202d\n",
      "2020/06/23 07:01:45 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/06/23 07:01:45 sshd inside container not required for job, skipping setup.\n",
      "2020/06/23 07:01:45 All App Insights Logs was send successfully\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_8670620c0c73952bf6a4abf9aa164b0d774f783ac03bcc0b47e0643edd436355_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Entering job preparation. Current time:2020-06-23T07:01:45.845699\n",
      "Starting job preparation. Current time:2020-06-23T07:01:46.636432\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: 5aaa6c6d-f82e-4f93-a510-f0934b26f87f\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 62\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "downloadDataStore - Download from datastores if requested.\n",
      "Entering context manager injector. Current time:2020-06-23T07:01:48.425358\n",
      "downloadDataStore completed\n",
      "Job preparation is complete. Current time:2020-06-23T07:01:49.310902\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Entering context manager injector. Current time:2020-06-23T07:01:50.636259\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 119\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ prepare.py ] with arguments: []\n",
      "After variable expansion, calling script [ prepare.py ] with arguments: []\n",
      "\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 119\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_8670620c0c73952bf6a4abf9aa164b0d774f783ac03bcc0b47e0643edd436355_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Entering job release. Current time:2020-06-23T07:09:56.582468\n",
      "Starting job release. Current time:2020-06-23T07:09:57.646108\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 410\n",
      "Entering context manager injector. Current time:2020-06-23T07:09:57.671417\n",
      "Job release is complete. Current time:2020-06-23T07:09:59.377889\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: KerasPrediction_1592895405_905719ed\n",
      "Web View: https://ml.azure.com/experiments/KerasPrediction/runs/KerasPrediction_1592895405_905719ed?wsid=/subscriptions/793146d9-d4dc-4a73-9728-76c4ffd0cc0d/resourcegroups/rg_dynamics_test/workspaces/resdynml1test\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'KerasPrediction_1592895405_905719ed',\n",
       " 'target': 'mlcompute',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-06-23T07:00:41.832753Z',\n",
       " 'endTimeUtc': '2020-06-23T07:10:13.405927Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'b8069286-ce5f-4d89-ae63-242dd90b4bf5',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '02e6cb83-4d0c-42b2-bbef-e103c74b3a3c'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'df_raw', 'mechanism': 'Direct'}}, {'dataset': {'id': '88af5740-1a1b-4e09-8129-d3c538680909'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'symptomcodes', 'mechanism': 'Direct'}}],\n",
       " 'runDefinition': {'script': 'prepare.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'mlcompute',\n",
       "  'dataReferences': {},\n",
       "  'data': {'df_raw': {'dataLocation': {'dataset': {'id': '02e6cb83-4d0c-42b2-bbef-e103c74b3a3c',\n",
       "      'name': None,\n",
       "      'version': None},\n",
       "     'dataPath': None},\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'df_raw',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False},\n",
       "   'symptomcodes': {'dataLocation': {'dataset': {'id': '88af5740-1a1b-4e09-8129-d3c538680909',\n",
       "      'name': None,\n",
       "      'version': None},\n",
       "     'dataPath': None},\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'symptomcodes',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'WILO_POC_Keras',\n",
       "   'version': '1',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'azureml-dataprep[pandas,fuse]',\n",
       "        'pyarrow==0.12.0',\n",
       "        'joblib==0.14.1',\n",
       "        'scikit-learn==0.20.3']},\n",
       "      'numpy==1.16.2'],\n",
       "     'name': 'azureml_42df74e95cf2de1f301b9fba9e8035c0'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'itpCompute': {'configuration': {}},\n",
       "  'cmAksCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_8670620c0c73952bf6a4abf9aa164b0d774f783ac03bcc0b47e0643edd436355_d.txt': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.KerasPrediction_1592895405_905719ed/azureml-logs/55_azureml-execution-tvmps_8670620c0c73952bf6a4abf9aa164b0d774f783ac03bcc0b47e0643edd436355_d.txt?sv=2019-02-02&sr=b&sig=A5ayBSWf0Kl9go%2BV8Ueav0pgFYRNpQ7wh%2FDuz1K%2FPMU%3D&st=2020-06-23T07%3A00%3A14Z&se=2020-06-23T15%3A10%3A14Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_8670620c0c73952bf6a4abf9aa164b0d774f783ac03bcc0b47e0643edd436355_d.txt': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.KerasPrediction_1592895405_905719ed/azureml-logs/65_job_prep-tvmps_8670620c0c73952bf6a4abf9aa164b0d774f783ac03bcc0b47e0643edd436355_d.txt?sv=2019-02-02&sr=b&sig=nfAM%2FfCWgjeJw257NrCaNUJ%2FjCmSIsF%2FX7qgg1ayHWQ%3D&st=2020-06-23T07%3A00%3A14Z&se=2020-06-23T15%3A10%3A14Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.KerasPrediction_1592895405_905719ed/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=TR7gONnM04LLsiwmKf24hOERK%2F2RVKzEDxErb8wiryU%3D&st=2020-06-23T07%3A00%3A14Z&se=2020-06-23T15%3A10%3A14Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_8670620c0c73952bf6a4abf9aa164b0d774f783ac03bcc0b47e0643edd436355_d.txt': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.KerasPrediction_1592895405_905719ed/azureml-logs/75_job_post-tvmps_8670620c0c73952bf6a4abf9aa164b0d774f783ac03bcc0b47e0643edd436355_d.txt?sv=2019-02-02&sr=b&sig=%2FGVzmsEg5ZULUvIJJD7OxGnxlmV7lcFo%2BzqLmExAvE0%3D&st=2020-06-23T07%3A00%3A14Z&se=2020-06-23T15%3A10%3A14Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.KerasPrediction_1592895405_905719ed/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=OzThX3i4bItb4NGe2Q3Kmuv5RRBZ%2BhwOEff4TzZv810%3D&st=2020-06-23T07%3A00%3A14Z&se=2020-06-23T15%3A10%3A14Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.KerasPrediction_1592895405_905719ed/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=%2FhOdFw%2BDaT6yKQV7tyoppUFs0bmpFJ9rtLU8EnTOO6M%3D&st=2020-06-23T07%3A00%3A14Z&se=2020-06-23T15%3A10%3A14Z&sp=r',\n",
       "  'logs/azureml/119_azureml.log': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.KerasPrediction_1592895405_905719ed/logs/azureml/119_azureml.log?sv=2019-02-02&sr=b&sig=0IirUmGWSQAx3%2FOFWrjdY%2BqT%2FQPor6sLklwc8BnGBBM%3D&st=2020-06-23T07%3A00%3A14Z&se=2020-06-23T15%3A10%3A14Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.KerasPrediction_1592895405_905719ed/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=U%2ByXe2ZURUnn0Emn6QAwEgthwUVW9zRgh9mBxRCOB%2Bc%3D&st=2020-06-23T07%3A00%3A14Z&se=2020-06-23T15%3A10%3A14Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://resdynml1test6456542521.blob.core.windows.net/azureml/ExperimentRun/dcid.KerasPrediction_1592895405_905719ed/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=k9QmT45ifoRHEymNs6ujDK2QM2PumY3jff4rwQGNw5E%3D&st=2020-06-23T07%3A00%3A14Z&se=2020-06-23T15%3A10%3A14Z&sp=r'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = Experiment(ws, cfg['experiment_name'])\n",
    "run = exp.submit(est)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading artifacts/prepared_data.csv\n",
      "Uploaded artifacts/prepared_data.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', './KerasPrediction')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\",\n",
       "    \"SetColumnTypes\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"9d38370a-0d3f-49f0-a325-7afc729c35a4\",\n",
       "    \"name\": \"KerasPreparedData\",\n",
       "    \"version\": 3,\n",
       "    \"workspace\": \"Workspace.create(name='resdynml1test', subscription_id='793146d9-d4dc-4a73-9728-76c4ffd0cc0d', resource_group='rg_dynamics_test')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.download_file('outputs/prepared_data.csv', output_file_path='artifacts/prepared_data.csv')\n",
    "ds = ws.datastores[cfg['storage']]\n",
    "data_ref = ds.upload_files(['artifacts/prepared_data.csv'], target_path='./'+cfg['experiment_name'], overwrite=True)\n",
    "prepared_data_dataset = Dataset.Tabular.from_delimited_files(data_ref, separator=';', header=True, infer_column_types=True, set_column_types={'Month': DataType.to_string(), 'Daytime': DataType.to_string(), 'Weekday': DataType.to_string()})\n",
    "prepared_data_dataset.register(ws, cfg['prepared_data_dataset'], create_new_version=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
